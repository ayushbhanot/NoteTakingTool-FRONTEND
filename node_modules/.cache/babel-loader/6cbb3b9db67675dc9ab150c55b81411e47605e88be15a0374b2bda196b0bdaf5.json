{"ast":null,"code":"let mediaRecorder = null; // Declare globally\n\n// Function to check MediaRecorder support\nfunction checkMediaRecorderSupport() {\n  if (!window.MediaRecorder) {\n    console.error('MediaRecorder API not supported.');\n    alert('Your browser does not support recording features.');\n    return false; // Return false if unsupported\n  }\n  return true; // Return true if supported\n}\n\n// Early check for MediaRecorder support\nif (!checkMediaRecorderSupport()) {\n  alert('Your browser does not support the necessary recording features.');\n}\n\n// Start recording function\n/*export async function startRecording() {\n    console.log('Attempting to start recording...');\n    try {\n        // Capture both system audio and microphone audio\n        const micStream = await navigator.mediaDevices.getUserMedia({\n            audio: {\n                echoCancellation: false,\n                noiseSuppression: false,\n                sampleRate: 44100\n            }\n        });\n        console.log('Microphone stream acquired:', micStream);\n\n        // Since you're focusing on capturing audio (both mic and system), you can use micStream alone\n        const combinedStream = micStream; \n        console.log('Combined stream:', combinedStream);\n\n        if (combinedStream.getAudioTracks().length === 0) {\n            throw new Error('Combined stream has no audio tracks.');\n        }\n\n        // Initialize MediaRecorder with combined audio stream\n        mediaRecorder = new MediaRecorder(combinedStream);\n        console.log('MediaRecorder initialized:', mediaRecorder);\n\n        let audioChunks = [];\n        mediaRecorder.ondataavailable = (event) => {\n            if (event.data.size > 0) {\n                audioChunks.push(event.data);\n                console.log('Audio chunk available:', event.data);\n            }\n        };\n\n        mediaRecorder.onstart = () => {\n            console.log('Recording started.');\n        };\n\n        mediaRecorder.onstop = () => {\n            console.log('Recording stopped.');\n            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });\n            processAudioChunk(audioBlob);  // Send audio to backend for processing\n        };\n\n        mediaRecorder.onerror = (event) => {\n            console.error('MediaRecorder error:', event.error);\n        };\n\n        // Start the recording\n        mediaRecorder.start();\n    } catch (error) {\n        console.error('Error capturing audio:', error);\n    }\n}*/\n\n// Stop recording function\nexport function stopRecording() {\n  if (mediaRecorder) {\n    if (mediaRecorder.state !== 'inactive') {\n      console.log('Stopping recording...');\n      mediaRecorder.stop();\n    } else {\n      console.error('MediaRecorder is inactive.');\n    }\n  } else {\n    console.error('No MediaRecorder instance found.');\n  }\n}\n\n// Function to process audio and send to backend\nexport const processAudioChunk = async audioBlob => {\n  if (!(audioBlob instanceof Blob)) {\n    console.error('audioBlob is not a Blob instance.');\n    return;\n  }\n  const formData = new FormData();\n  formData.append('audio', audioBlob, 'audio.webm'); // Make sure format matches what backend expects\n\n  try {\n    const response = await fetch('http://localhost:3001/transcribe', {\n      method: 'POST',\n      body: formData\n    });\n    if (!response.ok) {\n      throw new Error(`Server error: ${response.status}`);\n    }\n    const result = await response.json();\n    console.log('Transcription result:', result);\n  } catch (error) {\n    console.error('Error sending audio to backend:', error);\n  }\n};\n\n// Additional browser support checks\nif (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {\n  alert('Your browser does not support the necessary APIs for recording.');\n}","map":{"version":3,"names":["mediaRecorder","checkMediaRecorderSupport","window","MediaRecorder","console","error","alert","stopRecording","state","log","stop","processAudioChunk","audioBlob","Blob","formData","FormData","append","response","fetch","method","body","ok","Error","status","result","json","navigator","mediaDevices","getUserMedia"],"sources":["/Users/ayushbhanot/Documents/Coding/Riipen/AITranscriptionApp/aitranscriptionapp/src/services/audioRecording.js"],"sourcesContent":["let mediaRecorder = null; // Declare globally\n\n// Function to check MediaRecorder support\nfunction checkMediaRecorderSupport() {\n    if (!window.MediaRecorder) {\n        console.error('MediaRecorder API not supported.');\n        alert('Your browser does not support recording features.');\n        return false;  // Return false if unsupported\n    }\n    return true;  // Return true if supported\n}\n\n// Early check for MediaRecorder support\nif (!checkMediaRecorderSupport()) {\n    alert('Your browser does not support the necessary recording features.');\n}\n\n// Start recording function\n/*export async function startRecording() {\n    console.log('Attempting to start recording...');\n    try {\n        // Capture both system audio and microphone audio\n        const micStream = await navigator.mediaDevices.getUserMedia({\n            audio: {\n                echoCancellation: false,\n                noiseSuppression: false,\n                sampleRate: 44100\n            }\n        });\n        console.log('Microphone stream acquired:', micStream);\n\n        // Since you're focusing on capturing audio (both mic and system), you can use micStream alone\n        const combinedStream = micStream; \n        console.log('Combined stream:', combinedStream);\n\n        if (combinedStream.getAudioTracks().length === 0) {\n            throw new Error('Combined stream has no audio tracks.');\n        }\n\n        // Initialize MediaRecorder with combined audio stream\n        mediaRecorder = new MediaRecorder(combinedStream);\n        console.log('MediaRecorder initialized:', mediaRecorder);\n\n        let audioChunks = [];\n        mediaRecorder.ondataavailable = (event) => {\n            if (event.data.size > 0) {\n                audioChunks.push(event.data);\n                console.log('Audio chunk available:', event.data);\n            }\n        };\n\n        mediaRecorder.onstart = () => {\n            console.log('Recording started.');\n        };\n\n        mediaRecorder.onstop = () => {\n            console.log('Recording stopped.');\n            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });\n            processAudioChunk(audioBlob);  // Send audio to backend for processing\n        };\n\n        mediaRecorder.onerror = (event) => {\n            console.error('MediaRecorder error:', event.error);\n        };\n\n        // Start the recording\n        mediaRecorder.start();\n    } catch (error) {\n        console.error('Error capturing audio:', error);\n    }\n}*/\n\n// Stop recording function\nexport function stopRecording() {\n    if (mediaRecorder) {\n        if (mediaRecorder.state !== 'inactive') {\n            console.log('Stopping recording...');\n            mediaRecorder.stop();\n        } else {\n            console.error('MediaRecorder is inactive.');\n        }\n    } else {\n        console.error('No MediaRecorder instance found.');\n    }\n}\n\n// Function to process audio and send to backend\nexport const processAudioChunk = async (audioBlob) => {\n    if (!(audioBlob instanceof Blob)) {\n        console.error('audioBlob is not a Blob instance.');\n        return;\n    }\n\n    const formData = new FormData();\n    formData.append('audio', audioBlob, 'audio.webm');  // Make sure format matches what backend expects\n\n    try {\n        const response = await fetch('http://localhost:3001/transcribe', {\n            method: 'POST',\n            body: formData,\n        });\n\n        if (!response.ok) {\n            throw new Error(`Server error: ${response.status}`);\n        }\n\n        const result = await response.json();\n        console.log('Transcription result:', result);\n    } catch (error) {\n        console.error('Error sending audio to backend:', error);\n    }\n};\n\n// Additional browser support checks\nif (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {\n    alert('Your browser does not support the necessary APIs for recording.');\n}\n"],"mappings":"AAAA,IAAIA,aAAa,GAAG,IAAI,CAAC,CAAC;;AAE1B;AACA,SAASC,yBAAyBA,CAAA,EAAG;EACjC,IAAI,CAACC,MAAM,CAACC,aAAa,EAAE;IACvBC,OAAO,CAACC,KAAK,CAAC,kCAAkC,CAAC;IACjDC,KAAK,CAAC,mDAAmD,CAAC;IAC1D,OAAO,KAAK,CAAC,CAAE;EACnB;EACA,OAAO,IAAI,CAAC,CAAE;AAClB;;AAEA;AACA,IAAI,CAACL,yBAAyB,CAAC,CAAC,EAAE;EAC9BK,KAAK,CAAC,iEAAiE,CAAC;AAC5E;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,OAAO,SAASC,aAAaA,CAAA,EAAG;EAC5B,IAAIP,aAAa,EAAE;IACf,IAAIA,aAAa,CAACQ,KAAK,KAAK,UAAU,EAAE;MACpCJ,OAAO,CAACK,GAAG,CAAC,uBAAuB,CAAC;MACpCT,aAAa,CAACU,IAAI,CAAC,CAAC;IACxB,CAAC,MAAM;MACHN,OAAO,CAACC,KAAK,CAAC,4BAA4B,CAAC;IAC/C;EACJ,CAAC,MAAM;IACHD,OAAO,CAACC,KAAK,CAAC,kCAAkC,CAAC;EACrD;AACJ;;AAEA;AACA,OAAO,MAAMM,iBAAiB,GAAG,MAAOC,SAAS,IAAK;EAClD,IAAI,EAAEA,SAAS,YAAYC,IAAI,CAAC,EAAE;IAC9BT,OAAO,CAACC,KAAK,CAAC,mCAAmC,CAAC;IAClD;EACJ;EAEA,MAAMS,QAAQ,GAAG,IAAIC,QAAQ,CAAC,CAAC;EAC/BD,QAAQ,CAACE,MAAM,CAAC,OAAO,EAAEJ,SAAS,EAAE,YAAY,CAAC,CAAC,CAAE;;EAEpD,IAAI;IACA,MAAMK,QAAQ,GAAG,MAAMC,KAAK,CAAC,kCAAkC,EAAE;MAC7DC,MAAM,EAAE,MAAM;MACdC,IAAI,EAAEN;IACV,CAAC,CAAC;IAEF,IAAI,CAACG,QAAQ,CAACI,EAAE,EAAE;MACd,MAAM,IAAIC,KAAK,CAAC,iBAAiBL,QAAQ,CAACM,MAAM,EAAE,CAAC;IACvD;IAEA,MAAMC,MAAM,GAAG,MAAMP,QAAQ,CAACQ,IAAI,CAAC,CAAC;IACpCrB,OAAO,CAACK,GAAG,CAAC,uBAAuB,EAAEe,MAAM,CAAC;EAChD,CAAC,CAAC,OAAOnB,KAAK,EAAE;IACZD,OAAO,CAACC,KAAK,CAAC,iCAAiC,EAAEA,KAAK,CAAC;EAC3D;AACJ,CAAC;;AAED;AACA,IAAI,CAACqB,SAAS,CAACC,YAAY,IAAI,CAACD,SAAS,CAACC,YAAY,CAACC,YAAY,EAAE;EACjEtB,KAAK,CAAC,iEAAiE,CAAC;AAC5E","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}