{"ast":null,"code":"var _jsxFileName = \"/Users/ayushbhanot/Documents/Coding/Riipen/AITranscriptionApp/aitranscriptionapp/src/App.js\",\n  _s = $RefreshSig$();\n/*import React, { useState } from 'react';\nimport { startSpeechRecognition, stopSpeechRecognition } from './services/audioRecording'; // Adjust path as needed\n\nfunction App() {\n    const [isRecording, setIsRecording] = useState(false);\n\n    const handleStartRecording = async () => {\n        if (isRecording) return; // Prevent starting a new recording if one is already active\n        setIsRecording(true);\n        try {\n            await startSpeechRecognition();\n        } catch (error) {\n            console.error(\"Error starting speech recognition:\", error);\n            setIsRecording(false);\n        }\n    };\n\n    const handleStopRecording = async () => {\n        if (!isRecording) return; // Prevent stopping if no recording is active\n        try {\n            await stopSpeechRecognition();\n        } catch (error) {\n            console.error(\"Error stopping speech recognition:\", error);\n        } finally {\n            setIsRecording(false);\n        }\n    };\n\n    return (\n        <div className=\"App\">\n            <h1>Zoom/Google Meet Audio Recorder</h1>\n            <button onClick={handleStartRecording} disabled={isRecording}>\n                Start Speech Recognition\n            </button>\n            <button onClick={handleStopRecording} disabled={!isRecording}>\n                Stop Speech Recognition\n            </button>\n        </div>\n    );\n}\n\nexport default App;\n*/\n/* COMMENTED OUT MEDIARECORDER-BASED HANDLERS */\nimport React, { useState, useEffect } from 'react';\nimport { startRecording, stopRecording, generateNotesFromTranscript } from './services/audioRecording';\nimport NotesUI from './components/NotesUI';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nlet combinedTranscript = '';\nconst App = () => {\n  _s();\n  const [generatedNotes, setGeneratedNotes] = useState({}); // State to hold the notes\n  const [isRecording, setIsRecording] = useState(false); // State to manage recording\n\n  // Function to handle starting the recording\n  const handleStartRecording = async () => {\n    if (!isRecording) {\n      setIsRecording(true); // Set recording to true to disable start button\n      await startRecording(setGeneratedNotes); // Pass setGeneratedNotes to update notes\n    }\n  };\n\n  // Function to handle stopping the recording\n  const handleStopRecording = async () => {\n    if (isRecording) {\n      setIsRecording(false); // Disable start button while processing\n\n      try {\n        await stopRecording(); // Wait for all blobs to finish processing\n\n        if (combinedTranscript && combinedTranscript.trim() !== \"\") {\n          console.log('Final Combined Transcript:', combinedTranscript);\n\n          // Generate notes from the combined transcript at the end\n          const organizedNotes = await generateNotesFromTranscript(combinedTranscript);\n          if (organizedNotes) {\n            setGeneratedNotes(organizedNotes); // Update notes in the UI\n          } else {\n            console.error('No organized notes were returned.');\n          }\n        } else {\n          console.error('Transcript is undefined or empty.');\n        }\n      } catch (error) {\n        console.error('Error while stopping recording:', error);\n      }\n    }\n  };\n\n  // Log whenever generated notes change\n  useEffect(() => {\n    console.log(\"Generated Notes updated in App:\", generatedNotes);\n  }, [generatedNotes]);\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: [/*#__PURE__*/_jsxDEV(\"h1\", {\n      children: \"Audio Notes\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 98,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n      onClick: handleStartRecording,\n      disabled: isRecording,\n      children: \"Start Recording\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 100,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n      onClick: handleStopRecording,\n      disabled: !isRecording,\n      children: \"Stop Recording\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 103,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(NotesUI, {\n      notes: generatedNotes\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 108,\n      columnNumber: 13\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 97,\n    columnNumber: 9\n  }, this);\n};\n_s(App, \"Q+0pOdNjRwLyR7jXRV1fqddLX1M=\");\n_c = App;\nexport default App;\nvar _c;\n$RefreshReg$(_c, \"App\");","map":{"version":3,"names":["React","useState","useEffect","startRecording","stopRecording","generateNotesFromTranscript","NotesUI","jsxDEV","_jsxDEV","combinedTranscript","App","_s","generatedNotes","setGeneratedNotes","isRecording","setIsRecording","handleStartRecording","handleStopRecording","trim","console","log","organizedNotes","error","children","fileName","_jsxFileName","lineNumber","columnNumber","onClick","disabled","notes","_c","$RefreshReg$"],"sources":["/Users/ayushbhanot/Documents/Coding/Riipen/AITranscriptionApp/aitranscriptionapp/src/App.js"],"sourcesContent":["/*import React, { useState } from 'react';\nimport { startSpeechRecognition, stopSpeechRecognition } from './services/audioRecording'; // Adjust path as needed\n\nfunction App() {\n    const [isRecording, setIsRecording] = useState(false);\n\n    const handleStartRecording = async () => {\n        if (isRecording) return; // Prevent starting a new recording if one is already active\n        setIsRecording(true);\n        try {\n            await startSpeechRecognition();\n        } catch (error) {\n            console.error(\"Error starting speech recognition:\", error);\n            setIsRecording(false);\n        }\n    };\n\n    const handleStopRecording = async () => {\n        if (!isRecording) return; // Prevent stopping if no recording is active\n        try {\n            await stopSpeechRecognition();\n        } catch (error) {\n            console.error(\"Error stopping speech recognition:\", error);\n        } finally {\n            setIsRecording(false);\n        }\n    };\n\n    return (\n        <div className=\"App\">\n            <h1>Zoom/Google Meet Audio Recorder</h1>\n            <button onClick={handleStartRecording} disabled={isRecording}>\n                Start Speech Recognition\n            </button>\n            <button onClick={handleStopRecording} disabled={!isRecording}>\n                Stop Speech Recognition\n            </button>\n        </div>\n    );\n}\n\nexport default App;\n*/\n/* COMMENTED OUT MEDIARECORDER-BASED HANDLERS */\nimport React, { useState, useEffect } from 'react';\nimport { startRecording, stopRecording, generateNotesFromTranscript } from './services/audioRecording';\nimport NotesUI from './components/NotesUI';\nlet combinedTranscript = '';\nconst App = () => {\n    const [generatedNotes, setGeneratedNotes] = useState({});  // State to hold the notes\n    const [isRecording, setIsRecording] = useState(false);     // State to manage recording\n\n    // Function to handle starting the recording\n    const handleStartRecording = async () => {\n        if (!isRecording) {\n            setIsRecording(true);  // Set recording to true to disable start button\n            await startRecording(setGeneratedNotes);  // Pass setGeneratedNotes to update notes\n        }\n    };\n\n    // Function to handle stopping the recording\n    const handleStopRecording = async () => {\n        if (isRecording) {\n            setIsRecording(false);  // Disable start button while processing\n            \n            try {\n                await stopRecording();  // Wait for all blobs to finish processing\n        \n                if (combinedTranscript && combinedTranscript.trim() !== \"\") {\n                    console.log('Final Combined Transcript:', combinedTranscript);\n                    \n                    // Generate notes from the combined transcript at the end\n                    const organizedNotes = await generateNotesFromTranscript(combinedTranscript);  \n                    if (organizedNotes) {\n                        setGeneratedNotes(organizedNotes);  // Update notes in the UI\n                    } else {\n                        console.error('No organized notes were returned.');\n                    }\n                } else {\n                    console.error('Transcript is undefined or empty.');\n                }\n            } catch (error) {\n                console.error('Error while stopping recording:', error);\n            }\n        }\n    };\n    \n    \n    \n\n    // Log whenever generated notes change\n    useEffect(() => {\n        console.log(\"Generated Notes updated in App:\", generatedNotes);\n    }, [generatedNotes]);\n\n    return (\n        <div>\n            <h1>Audio Notes</h1>\n            \n            <button onClick={handleStartRecording} disabled={isRecording}>\n                Start Recording\n            </button>\n            <button onClick={handleStopRecording} disabled={!isRecording}>\n                Stop Recording\n            </button>\n            \n            {/* Render Notes UI and pass down generated notes */}\n            <NotesUI notes={generatedNotes} />\n        </div>\n    );\n};\n\nexport default App;\n\n"],"mappings":";;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,SAAS,QAAQ,OAAO;AAClD,SAASC,cAAc,EAAEC,aAAa,EAAEC,2BAA2B,QAAQ,2BAA2B;AACtG,OAAOC,OAAO,MAAM,sBAAsB;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAC3C,IAAIC,kBAAkB,GAAG,EAAE;AAC3B,MAAMC,GAAG,GAAGA,CAAA,KAAM;EAAAC,EAAA;EACd,MAAM,CAACC,cAAc,EAAEC,iBAAiB,CAAC,GAAGZ,QAAQ,CAAC,CAAC,CAAC,CAAC,CAAC,CAAE;EAC3D,MAAM,CAACa,WAAW,EAAEC,cAAc,CAAC,GAAGd,QAAQ,CAAC,KAAK,CAAC,CAAC,CAAK;;EAE3D;EACA,MAAMe,oBAAoB,GAAG,MAAAA,CAAA,KAAY;IACrC,IAAI,CAACF,WAAW,EAAE;MACdC,cAAc,CAAC,IAAI,CAAC,CAAC,CAAE;MACvB,MAAMZ,cAAc,CAACU,iBAAiB,CAAC,CAAC,CAAE;IAC9C;EACJ,CAAC;;EAED;EACA,MAAMI,mBAAmB,GAAG,MAAAA,CAAA,KAAY;IACpC,IAAIH,WAAW,EAAE;MACbC,cAAc,CAAC,KAAK,CAAC,CAAC,CAAE;;MAExB,IAAI;QACA,MAAMX,aAAa,CAAC,CAAC,CAAC,CAAE;;QAExB,IAAIK,kBAAkB,IAAIA,kBAAkB,CAACS,IAAI,CAAC,CAAC,KAAK,EAAE,EAAE;UACxDC,OAAO,CAACC,GAAG,CAAC,4BAA4B,EAAEX,kBAAkB,CAAC;;UAE7D;UACA,MAAMY,cAAc,GAAG,MAAMhB,2BAA2B,CAACI,kBAAkB,CAAC;UAC5E,IAAIY,cAAc,EAAE;YAChBR,iBAAiB,CAACQ,cAAc,CAAC,CAAC,CAAE;UACxC,CAAC,MAAM;YACHF,OAAO,CAACG,KAAK,CAAC,mCAAmC,CAAC;UACtD;QACJ,CAAC,MAAM;UACHH,OAAO,CAACG,KAAK,CAAC,mCAAmC,CAAC;QACtD;MACJ,CAAC,CAAC,OAAOA,KAAK,EAAE;QACZH,OAAO,CAACG,KAAK,CAAC,iCAAiC,EAAEA,KAAK,CAAC;MAC3D;IACJ;EACJ,CAAC;;EAKD;EACApB,SAAS,CAAC,MAAM;IACZiB,OAAO,CAACC,GAAG,CAAC,iCAAiC,EAAER,cAAc,CAAC;EAClE,CAAC,EAAE,CAACA,cAAc,CAAC,CAAC;EAEpB,oBACIJ,OAAA;IAAAe,QAAA,gBACIf,OAAA;MAAAe,QAAA,EAAI;IAAW;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAI,CAAC,eAEpBnB,OAAA;MAAQoB,OAAO,EAAEZ,oBAAqB;MAACa,QAAQ,EAAEf,WAAY;MAAAS,QAAA,EAAC;IAE9D;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAQ,CAAC,eACTnB,OAAA;MAAQoB,OAAO,EAAEX,mBAAoB;MAACY,QAAQ,EAAE,CAACf,WAAY;MAAAS,QAAA,EAAC;IAE9D;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAQ,CAAC,eAGTnB,OAAA,CAACF,OAAO;MAACwB,KAAK,EAAElB;IAAe;MAAAY,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAE,CAAC;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACjC,CAAC;AAEd,CAAC;AAAChB,EAAA,CA9DID,GAAG;AAAAqB,EAAA,GAAHrB,GAAG;AAgET,eAAeA,GAAG;AAAC,IAAAqB,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}