{"ast":null,"code":"// let mediaRecorder = null; // Declare globally (commented out, we won't use MediaRecorder)\n\n// Function to check WebkitSpeechRecognition support\n/*function checkSpeechRecognitionSupport() {\n    window.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n    if (!window.SpeechRecognition) {\n        console.error('SpeechRecognition API not supported.');\n        alert('Your browser does not support speech recognition features.');\n        return false;\n    }\n    return true;\n}\n\n// Check for WebkitSpeechRecognition support early\nif (!checkSpeechRecognitionSupport()) {\n    alert('Your browser does not support the necessary speech recognition features.');\n}\n\n// Initialize WebkitSpeechRecognition\nconst recognition = new window.SpeechRecognition();\nrecognition.continuous = true;\nrecognition.interimResults = true; // Set to true to capture partial results\nrecognition.lang = 'en-US';\nlet isRecognitionRunning = false;\nlet finalTranscript = '';  // Store final transcript globally\n\n// Function to request microphone permission\nasync function requestMicPermission() {\n    try {\n        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n        console.log('Microphone permission granted');\n        stream.getTracks().forEach(track => track.stop());  // Stop the stream immediately\n        return true;\n    } catch (error) {\n        console.error('Microphone permission denied:', error);\n        alert('Microphone access is required for speech recognition.');\n        return false;\n    }\n}\n\n// Start speech recognition function\nexport async function startSpeechRecognition() {\n    const permissionGranted = await requestMicPermission();  // Ensure permission is granted\n    if (!permissionGranted) return;\n\n    if (isRecognitionRunning) {\n        console.error(\"Speech recognition is already running.\");\n        return;\n    }\n    try {\n        finalTranscript = '';  // Clear transcript on new session\n        recognition.start();\n        isRecognitionRunning = true;\n        console.log('Speech recognition started.');\n    } catch (error) {\n        console.error('Error starting speech recognition:', error);\n    }\n}\n\n// Stop speech recognition function\nexport function stopSpeechRecognition() {\n    if (!isRecognitionRunning) {\n        console.error(\"Speech recognition is not running.\");\n        return;\n    }\n    console.log('Stopping speech recognition...');\n    recognition.stop();\n}\n\n// Handle when recognition ends\nrecognition.onend = () => {\n    isRecognitionRunning = false;\n    console.log('Speech recognition stopped.');\n    \n    // Send the final transcript to backend for transcription when stopped\n    if (finalTranscript) {\n        processTranscript(finalTranscript);  // Send final transcript to backend\n    } else {\n        console.error(\"No transcript available to send.\");\n    }\n};\n\n// Handle when recognition is aborted\nrecognition.onabort = (event) => {\n    console.error('Speech recognition was aborted:', event);\n    // Optionally, restart recognition if needed\n    setTimeout(() => {\n        console.log('Attempting to restart speech recognition...');\n        startSpeechRecognition();\n    }, 1000);  // Delay to prevent immediate restart\n};\n\n// Process the transcript and send to backend\n// Process the transcript and send to backend\nexport const processTranscript = async (transcript) => {\n    try {\n        // Send as JSON, not FormData, because the backend likely expects a JSON payload\n        const response = await fetch('http://localhost:3001/generateNotes', {\n            method: 'POST',\n            headers: {\n                'Content-Type': 'application/json',\n            },\n            body: JSON.stringify({ transcript }),  // Send the transcript as JSON\n        });\n\n        if (!response.ok) {\n            throw new Error(`Server error: ${response.status}`);\n        }\n\n        const result = await response.json();\n        console.log('Generated notes:', result);\n    } catch (error) {\n        console.error('Error sending transcript to backend:', error);\n    }\n};\n\n\n// Event handler for when recognition results are available\nrecognition.onresult = (event) => {\n    let interimTranscript = '';\n\n    for (let i = event.resultIndex; i < event.results.length; i++) {\n        const result = event.results[i];\n        if (result.isFinal) {\n            finalTranscript += result[0].transcript;\n        } else {\n            interimTranscript += result[0].transcript;\n        }\n    }\n\n    console.log('Interim Transcript:', interimTranscript);\n    console.log('Final Transcript:', finalTranscript);  // Only append the final result once\n};\n\nrecognition.onerror = (event) => {\n    console.error('Speech Recognition Error:', event.error);\n\n    // Handle specific \"no-speech\" error\n    if (event.error === 'no-speech') {\n        console.log('No speech detected. Please try speaking more clearly.');\n        alert('No speech detected. Please try again.');\n        // Optionally, restart the recognition\n        setTimeout(() => {\n            console.log('Restarting speech recognition after no-speech error...');\n            startSpeechRecognition();\n        }, 1000);  // Delay before restarting\n    }\n\n    if (event.error === 'audio-capture') {\n        console.error('Microphone access issue.');\n        alert('Please check your microphone permissions.');\n    }\n};\nrecognition.onabort = (event) => {\n    console.error('Speech recognition was aborted:', event);\n    // Optionally restart recognition\n    setTimeout(() => {\n        console.log('Attempting to restart speech recognition...');\n        startSpeechRecognition();\n    }, 1000);  // Delay to prevent immediate restart\n};\n*/\n\n// COMMENTED OUT MEDIARECORDER CODE\n\nlet mediaRecorder = null; // Declare MediaRecorder globally\nlet combinedTranscript = \"\"; // String to hold combined transcript\nlet audioChunks = []; // Store audio chunks\n\nexport async function startRecording() {\n  console.log('Attempting to start recording...');\n  combinedTranscript = \"\"; // Reset combined transcript on new recording\n  try {\n    const micStream = await navigator.mediaDevices.getUserMedia({\n      audio: {\n        echoCancellation: false,\n        noiseSuppression: false,\n        sampleRate: 44100\n      }\n    });\n    console.log('Microphone stream acquired:', micStream);\n    const combinedStream = micStream;\n    console.log('Combined stream:', combinedStream);\n    if (combinedStream.getAudioTracks().length === 0) {\n      throw new Error('Combined stream has no audio tracks.');\n    }\n    let options = {\n      mimeType: 'audio/webm; codecs=opus'\n    };\n    if (!MediaRecorder.isTypeSupported(options.mimeType)) {\n      options = {\n        mimeType: 'audio/webm'\n      };\n    }\n    if (!MediaRecorder.isTypeSupported(options.mimeType)) {\n      options = {\n        mimeType: 'audio/mp4'\n      };\n    }\n    if (!MediaRecorder.isTypeSupported(options.mimeType)) {\n      options = {};\n    }\n    mediaRecorder = new MediaRecorder(combinedStream, options);\n    console.log('MediaRecorder initialized:', mediaRecorder);\n\n    // Clear audio chunks before starting a new recording\n    audioChunks = [];\n    mediaRecorder.ondataavailable = event => {\n      if (event.data.size > 0) {\n        audioChunks.push(event.data); // Store each chunk\n        console.log('Audio chunk available:', event.data);\n      }\n    };\n    mediaRecorder.onstart = () => {\n      console.log('Recording started.');\n    };\n    mediaRecorder.onstop = async () => {\n      console.log('Recording stopped.');\n      const audioBlob = new Blob(audioChunks, {\n        type: options.mimeType || 'audio/webm'\n      });\n      console.log('Audio Blob size:', audioBlob.size);\n      if (audioBlob.size > 0) {\n        await processAudioChunk(audioBlob); // Make sure this finishes before moving forward\n        console.log(\"Combined Transcript after processing audio:\", combinedTranscript);\n        if (combinedTranscript && combinedTranscript.trim()) {\n          await generateNotesFromTranscript(); // This uses the final transcript\n        } else {\n          console.error('No transcript available to generate notes.');\n        }\n      } else {\n        console.error('Audio Blob is empty, not sending to backend');\n      }\n    };\n    mediaRecorder.onerror = event => {\n      console.error('MediaRecorder error:', event.error);\n    };\n\n    // Start recording with a timeslice of 30 seconds (30000 ms) to generate chunks every 30 seconds\n    mediaRecorder.start(30000); // Collect blobs every 30 seconds\n  } catch (error) {\n    console.error('Error capturing audio:', error);\n  }\n}\nexport function stopRecording() {\n  return new Promise((resolve, reject) => {\n    if (mediaRecorder) {\n      if (mediaRecorder.state !== 'inactive') {\n        console.log('Stopping recording...');\n        mediaRecorder.stop();\n        mediaRecorder.onstop = async () => {\n          console.log('Recording stopped.');\n          const audioBlob = new Blob(audioChunks, {\n            type: mediaRecorder.mimeType || 'audio/webm'\n          });\n          if (audioBlob.size > 0) {\n            try {\n              // Process the final audio blob and update the transcript\n              await processAudioChunk(audioBlob);\n\n              // Wait until the transcript is fully processed\n              if (combinedTranscript && combinedTranscript.trim() !== \"\") {\n                console.log('Final Combined Transcript:', combinedTranscript);\n                resolve(combinedTranscript); // Resolve with the final transcript\n              } else {\n                console.error('Transcript is undefined or empty after processing.');\n                reject('Transcript is undefined or empty after processing.');\n              }\n            } catch (error) {\n              console.error('Error processing audio chunk:', error);\n              reject('Error processing audio chunk.');\n            }\n          } else {\n            console.error('Audio Blob is empty, not sending to backend.');\n            reject('Audio Blob is empty.');\n          }\n        };\n      } else {\n        console.error('MediaRecorder is inactive.');\n        reject('MediaRecorder is inactive.');\n      }\n    } else {\n      console.error('No MediaRecorder instance found.');\n      reject('No MediaRecorder instance found.');\n    }\n  });\n}\n\n// Process the recorded audio chunk and send it to the backend for transcription\nexport async function processAudioChunk(audioBlob) {\n  console.log('Processing audio chunk for upload...');\n  const formData = new FormData();\n  formData.append('audio', audioBlob, 'recording.webm');\n  try {\n    const response = await fetch('http://localhost:3001/transcribe', {\n      method: 'POST',\n      body: formData\n    });\n    if (!response.ok) {\n      throw new Error(`Server error: ${response.status}`);\n    }\n    const result = await response.json();\n    console.log('Transcription result:', result);\n    if (result && result.transcription) {\n      combinedTranscript += \" \" + result.transcription.trim(); // Append transcription\n      console.log('Combined transcript:', combinedTranscript); // Add this line to log the combined transcript\n    } else {\n      console.error('Transcription is empty or undefined:', result);\n    }\n  } catch (error) {\n    console.error('Error uploading audio:', error);\n  }\n}\n\n// Function to send the combined transcript to the backend for note generation\n// Ensure `setGeneratedNotes` is properly passed as a prop or available in scope\n// Function to send the combined transcript to the backend for note generation\nexport async function generateNotesFromTranscript(combinedTranscript) {\n  if (!combinedTranscript || combinedTranscript.trim() === \"\") {\n    console.error('Transcript is undefined or empty.');\n    return;\n  }\n  console.log('Sending transcript:', combinedTranscript);\n  try {\n    const response = await fetch('http://localhost:3001/generateNotes', {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json'\n      },\n      body: JSON.stringify({\n        transcript: combinedTranscript\n      }) // Send the transcript\n    });\n    if (!response.ok) {\n      throw new Error(`Server error: ${response.status}`);\n    }\n    const result = await response.json();\n    console.log('Generated notes:', result.notes);\n    return result.notes;\n  } catch (error) {\n    console.error('Error generating notes:', error);\n  }\n}","map":{"version":3,"names":["mediaRecorder","combinedTranscript","audioChunks","startRecording","console","log","micStream","navigator","mediaDevices","getUserMedia","audio","echoCancellation","noiseSuppression","sampleRate","combinedStream","getAudioTracks","length","Error","options","mimeType","MediaRecorder","isTypeSupported","ondataavailable","event","data","size","push","onstart","onstop","audioBlob","Blob","type","processAudioChunk","trim","generateNotesFromTranscript","error","onerror","start","stopRecording","Promise","resolve","reject","state","stop","formData","FormData","append","response","fetch","method","body","ok","status","result","json","transcription","headers","JSON","stringify","transcript","notes"],"sources":["/Users/ayushbhanot/Documents/Coding/Riipen/AITranscriptionApp/aitranscriptionapp/src/services/audioRecording.js"],"sourcesContent":["// let mediaRecorder = null; // Declare globally (commented out, we won't use MediaRecorder)\n\n// Function to check WebkitSpeechRecognition support\n/*function checkSpeechRecognitionSupport() {\n    window.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n    if (!window.SpeechRecognition) {\n        console.error('SpeechRecognition API not supported.');\n        alert('Your browser does not support speech recognition features.');\n        return false;\n    }\n    return true;\n}\n\n// Check for WebkitSpeechRecognition support early\nif (!checkSpeechRecognitionSupport()) {\n    alert('Your browser does not support the necessary speech recognition features.');\n}\n\n// Initialize WebkitSpeechRecognition\nconst recognition = new window.SpeechRecognition();\nrecognition.continuous = true;\nrecognition.interimResults = true; // Set to true to capture partial results\nrecognition.lang = 'en-US';\nlet isRecognitionRunning = false;\nlet finalTranscript = '';  // Store final transcript globally\n\n// Function to request microphone permission\nasync function requestMicPermission() {\n    try {\n        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n        console.log('Microphone permission granted');\n        stream.getTracks().forEach(track => track.stop());  // Stop the stream immediately\n        return true;\n    } catch (error) {\n        console.error('Microphone permission denied:', error);\n        alert('Microphone access is required for speech recognition.');\n        return false;\n    }\n}\n\n// Start speech recognition function\nexport async function startSpeechRecognition() {\n    const permissionGranted = await requestMicPermission();  // Ensure permission is granted\n    if (!permissionGranted) return;\n\n    if (isRecognitionRunning) {\n        console.error(\"Speech recognition is already running.\");\n        return;\n    }\n    try {\n        finalTranscript = '';  // Clear transcript on new session\n        recognition.start();\n        isRecognitionRunning = true;\n        console.log('Speech recognition started.');\n    } catch (error) {\n        console.error('Error starting speech recognition:', error);\n    }\n}\n\n// Stop speech recognition function\nexport function stopSpeechRecognition() {\n    if (!isRecognitionRunning) {\n        console.error(\"Speech recognition is not running.\");\n        return;\n    }\n    console.log('Stopping speech recognition...');\n    recognition.stop();\n}\n\n// Handle when recognition ends\nrecognition.onend = () => {\n    isRecognitionRunning = false;\n    console.log('Speech recognition stopped.');\n    \n    // Send the final transcript to backend for transcription when stopped\n    if (finalTranscript) {\n        processTranscript(finalTranscript);  // Send final transcript to backend\n    } else {\n        console.error(\"No transcript available to send.\");\n    }\n};\n\n// Handle when recognition is aborted\nrecognition.onabort = (event) => {\n    console.error('Speech recognition was aborted:', event);\n    // Optionally, restart recognition if needed\n    setTimeout(() => {\n        console.log('Attempting to restart speech recognition...');\n        startSpeechRecognition();\n    }, 1000);  // Delay to prevent immediate restart\n};\n\n// Process the transcript and send to backend\n// Process the transcript and send to backend\nexport const processTranscript = async (transcript) => {\n    try {\n        // Send as JSON, not FormData, because the backend likely expects a JSON payload\n        const response = await fetch('http://localhost:3001/generateNotes', {\n            method: 'POST',\n            headers: {\n                'Content-Type': 'application/json',\n            },\n            body: JSON.stringify({ transcript }),  // Send the transcript as JSON\n        });\n\n        if (!response.ok) {\n            throw new Error(`Server error: ${response.status}`);\n        }\n\n        const result = await response.json();\n        console.log('Generated notes:', result);\n    } catch (error) {\n        console.error('Error sending transcript to backend:', error);\n    }\n};\n\n\n// Event handler for when recognition results are available\nrecognition.onresult = (event) => {\n    let interimTranscript = '';\n\n    for (let i = event.resultIndex; i < event.results.length; i++) {\n        const result = event.results[i];\n        if (result.isFinal) {\n            finalTranscript += result[0].transcript;\n        } else {\n            interimTranscript += result[0].transcript;\n        }\n    }\n\n    console.log('Interim Transcript:', interimTranscript);\n    console.log('Final Transcript:', finalTranscript);  // Only append the final result once\n};\n\nrecognition.onerror = (event) => {\n    console.error('Speech Recognition Error:', event.error);\n\n    // Handle specific \"no-speech\" error\n    if (event.error === 'no-speech') {\n        console.log('No speech detected. Please try speaking more clearly.');\n        alert('No speech detected. Please try again.');\n        // Optionally, restart the recognition\n        setTimeout(() => {\n            console.log('Restarting speech recognition after no-speech error...');\n            startSpeechRecognition();\n        }, 1000);  // Delay before restarting\n    }\n\n    if (event.error === 'audio-capture') {\n        console.error('Microphone access issue.');\n        alert('Please check your microphone permissions.');\n    }\n};\nrecognition.onabort = (event) => {\n    console.error('Speech recognition was aborted:', event);\n    // Optionally restart recognition\n    setTimeout(() => {\n        console.log('Attempting to restart speech recognition...');\n        startSpeechRecognition();\n    }, 1000);  // Delay to prevent immediate restart\n};\n*/\n\n// COMMENTED OUT MEDIARECORDER CODE\n\nlet mediaRecorder = null; // Declare MediaRecorder globally\nlet combinedTranscript = \"\"; // String to hold combined transcript\nlet audioChunks = []; // Store audio chunks\n\n\nexport async function startRecording() {\n    console.log('Attempting to start recording...');\n    combinedTranscript = \"\";  // Reset combined transcript on new recording\n    try {\n        const micStream = await navigator.mediaDevices.getUserMedia({\n            audio: {\n                echoCancellation: false,\n                noiseSuppression: false,\n                sampleRate: 44100\n            }\n        });\n        console.log('Microphone stream acquired:', micStream);\n\n        const combinedStream = micStream;\n        console.log('Combined stream:', combinedStream);\n\n        if (combinedStream.getAudioTracks().length === 0) {\n            throw new Error('Combined stream has no audio tracks.');\n        }\n\n        let options = { mimeType: 'audio/webm; codecs=opus' };\n        if (!MediaRecorder.isTypeSupported(options.mimeType)) {\n            options = { mimeType: 'audio/webm' };\n        }\n        if (!MediaRecorder.isTypeSupported(options.mimeType)) {\n            options = { mimeType: 'audio/mp4' };\n        }\n        if (!MediaRecorder.isTypeSupported(options.mimeType)) {\n            options = {};\n        }\n\n        mediaRecorder = new MediaRecorder(combinedStream, options);\n        console.log('MediaRecorder initialized:', mediaRecorder);\n\n        // Clear audio chunks before starting a new recording\n        audioChunks = [];\n\n        mediaRecorder.ondataavailable = (event) => {\n            if (event.data.size > 0) {\n                audioChunks.push(event.data); // Store each chunk\n                console.log('Audio chunk available:', event.data);\n            }\n        };\n\n        mediaRecorder.onstart = () => {\n            console.log('Recording started.');\n        };\n\n        mediaRecorder.onstop = async () => {\n            console.log('Recording stopped.');\n            const audioBlob = new Blob(audioChunks, { type: options.mimeType || 'audio/webm' });\n            console.log('Audio Blob size:', audioBlob.size);\n        \n            if (audioBlob.size > 0) {\n                await processAudioChunk(audioBlob);  // Make sure this finishes before moving forward\n                console.log(\"Combined Transcript after processing audio:\", combinedTranscript);\n        \n                if (combinedTranscript && combinedTranscript.trim()) {\n                    await generateNotesFromTranscript();  // This uses the final transcript\n                } else {\n                    console.error('No transcript available to generate notes.');\n                }\n            } else {\n                console.error('Audio Blob is empty, not sending to backend');\n            }\n        };\n        \n\n        mediaRecorder.onerror = (event) => {\n            console.error('MediaRecorder error:', event.error);\n        };\n\n        // Start recording with a timeslice of 30 seconds (30000 ms) to generate chunks every 30 seconds\n        mediaRecorder.start(30000);  // Collect blobs every 30 seconds\n    } catch (error) {\n        console.error('Error capturing audio:', error);\n    }\n}\n\nexport function stopRecording() {\n    return new Promise((resolve, reject) => {\n        if (mediaRecorder) {\n            if (mediaRecorder.state !== 'inactive') {\n                console.log('Stopping recording...');\n                mediaRecorder.stop();\n\n                mediaRecorder.onstop = async () => {\n                    console.log('Recording stopped.');\n                    const audioBlob = new Blob(audioChunks, { type: mediaRecorder.mimeType || 'audio/webm' });\n\n                    if (audioBlob.size > 0) {\n                        try {\n                            // Process the final audio blob and update the transcript\n                            await processAudioChunk(audioBlob);\n                            \n                            // Wait until the transcript is fully processed\n                            if (combinedTranscript && combinedTranscript.trim() !== \"\") {\n                                console.log('Final Combined Transcript:', combinedTranscript);\n                                resolve(combinedTranscript);  // Resolve with the final transcript\n                            } else {\n                                console.error('Transcript is undefined or empty after processing.');\n                                reject('Transcript is undefined or empty after processing.');\n                            }\n                        } catch (error) {\n                            console.error('Error processing audio chunk:', error);\n                            reject('Error processing audio chunk.');\n                        }\n                    } else {\n                        console.error('Audio Blob is empty, not sending to backend.');\n                        reject('Audio Blob is empty.');\n                    }\n                };\n            } else {\n                console.error('MediaRecorder is inactive.');\n                reject('MediaRecorder is inactive.');\n            }\n        } else {\n            console.error('No MediaRecorder instance found.');\n            reject('No MediaRecorder instance found.');\n        }\n    });\n}\n\n\n\n\n// Process the recorded audio chunk and send it to the backend for transcription\nexport async function processAudioChunk(audioBlob) {\n    console.log('Processing audio chunk for upload...');\n    const formData = new FormData();\n    formData.append('audio', audioBlob, 'recording.webm');\n\n    try {\n        const response = await fetch('http://localhost:3001/transcribe', {\n            method: 'POST',\n            body: formData,\n        });\n\n        if (!response.ok) {\n            throw new Error(`Server error: ${response.status}`);\n        }\n\n        const result = await response.json();\n        console.log('Transcription result:', result);\n\n        if (result && result.transcription) {\n            combinedTranscript += \" \" + result.transcription.trim(); // Append transcription\n            console.log('Combined transcript:', combinedTranscript); // Add this line to log the combined transcript\n        } else {\n            console.error('Transcription is empty or undefined:', result);\n        }\n    } catch (error) {\n        console.error('Error uploading audio:', error);\n    }\n}\n\n\n\n// Function to send the combined transcript to the backend for note generation\n// Ensure `setGeneratedNotes` is properly passed as a prop or available in scope\n// Function to send the combined transcript to the backend for note generation\nexport async function generateNotesFromTranscript(combinedTranscript) {\n    if (!combinedTranscript || combinedTranscript.trim() === \"\") {\n        console.error('Transcript is undefined or empty.');\n        return;\n    }\n\n    console.log('Sending transcript:', combinedTranscript);\n\n    try {\n        const response = await fetch('http://localhost:3001/generateNotes', {\n            method: 'POST',\n            headers: {\n                'Content-Type': 'application/json',\n            },\n            body: JSON.stringify({ transcript: combinedTranscript }),  // Send the transcript\n        });\n\n        if (!response.ok) {\n            throw new Error(`Server error: ${response.status}`);\n        }\n\n        const result = await response.json();\n        console.log('Generated notes:', result.notes);\n        return result.notes;\n    } catch (error) {\n        console.error('Error generating notes:', error);\n    }\n}\n\n\n\n\n"],"mappings":"AAAA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA,IAAIA,aAAa,GAAG,IAAI,CAAC,CAAC;AAC1B,IAAIC,kBAAkB,GAAG,EAAE,CAAC,CAAC;AAC7B,IAAIC,WAAW,GAAG,EAAE,CAAC,CAAC;;AAGtB,OAAO,eAAeC,cAAcA,CAAA,EAAG;EACnCC,OAAO,CAACC,GAAG,CAAC,kCAAkC,CAAC;EAC/CJ,kBAAkB,GAAG,EAAE,CAAC,CAAE;EAC1B,IAAI;IACA,MAAMK,SAAS,GAAG,MAAMC,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;MACxDC,KAAK,EAAE;QACHC,gBAAgB,EAAE,KAAK;QACvBC,gBAAgB,EAAE,KAAK;QACvBC,UAAU,EAAE;MAChB;IACJ,CAAC,CAAC;IACFT,OAAO,CAACC,GAAG,CAAC,6BAA6B,EAAEC,SAAS,CAAC;IAErD,MAAMQ,cAAc,GAAGR,SAAS;IAChCF,OAAO,CAACC,GAAG,CAAC,kBAAkB,EAAES,cAAc,CAAC;IAE/C,IAAIA,cAAc,CAACC,cAAc,CAAC,CAAC,CAACC,MAAM,KAAK,CAAC,EAAE;MAC9C,MAAM,IAAIC,KAAK,CAAC,sCAAsC,CAAC;IAC3D;IAEA,IAAIC,OAAO,GAAG;MAAEC,QAAQ,EAAE;IAA0B,CAAC;IACrD,IAAI,CAACC,aAAa,CAACC,eAAe,CAACH,OAAO,CAACC,QAAQ,CAAC,EAAE;MAClDD,OAAO,GAAG;QAAEC,QAAQ,EAAE;MAAa,CAAC;IACxC;IACA,IAAI,CAACC,aAAa,CAACC,eAAe,CAACH,OAAO,CAACC,QAAQ,CAAC,EAAE;MAClDD,OAAO,GAAG;QAAEC,QAAQ,EAAE;MAAY,CAAC;IACvC;IACA,IAAI,CAACC,aAAa,CAACC,eAAe,CAACH,OAAO,CAACC,QAAQ,CAAC,EAAE;MAClDD,OAAO,GAAG,CAAC,CAAC;IAChB;IAEAlB,aAAa,GAAG,IAAIoB,aAAa,CAACN,cAAc,EAAEI,OAAO,CAAC;IAC1Dd,OAAO,CAACC,GAAG,CAAC,4BAA4B,EAAEL,aAAa,CAAC;;IAExD;IACAE,WAAW,GAAG,EAAE;IAEhBF,aAAa,CAACsB,eAAe,GAAIC,KAAK,IAAK;MACvC,IAAIA,KAAK,CAACC,IAAI,CAACC,IAAI,GAAG,CAAC,EAAE;QACrBvB,WAAW,CAACwB,IAAI,CAACH,KAAK,CAACC,IAAI,CAAC,CAAC,CAAC;QAC9BpB,OAAO,CAACC,GAAG,CAAC,wBAAwB,EAAEkB,KAAK,CAACC,IAAI,CAAC;MACrD;IACJ,CAAC;IAEDxB,aAAa,CAAC2B,OAAO,GAAG,MAAM;MAC1BvB,OAAO,CAACC,GAAG,CAAC,oBAAoB,CAAC;IACrC,CAAC;IAEDL,aAAa,CAAC4B,MAAM,GAAG,YAAY;MAC/BxB,OAAO,CAACC,GAAG,CAAC,oBAAoB,CAAC;MACjC,MAAMwB,SAAS,GAAG,IAAIC,IAAI,CAAC5B,WAAW,EAAE;QAAE6B,IAAI,EAAEb,OAAO,CAACC,QAAQ,IAAI;MAAa,CAAC,CAAC;MACnFf,OAAO,CAACC,GAAG,CAAC,kBAAkB,EAAEwB,SAAS,CAACJ,IAAI,CAAC;MAE/C,IAAII,SAAS,CAACJ,IAAI,GAAG,CAAC,EAAE;QACpB,MAAMO,iBAAiB,CAACH,SAAS,CAAC,CAAC,CAAE;QACrCzB,OAAO,CAACC,GAAG,CAAC,6CAA6C,EAAEJ,kBAAkB,CAAC;QAE9E,IAAIA,kBAAkB,IAAIA,kBAAkB,CAACgC,IAAI,CAAC,CAAC,EAAE;UACjD,MAAMC,2BAA2B,CAAC,CAAC,CAAC,CAAE;QAC1C,CAAC,MAAM;UACH9B,OAAO,CAAC+B,KAAK,CAAC,4CAA4C,CAAC;QAC/D;MACJ,CAAC,MAAM;QACH/B,OAAO,CAAC+B,KAAK,CAAC,6CAA6C,CAAC;MAChE;IACJ,CAAC;IAGDnC,aAAa,CAACoC,OAAO,GAAIb,KAAK,IAAK;MAC/BnB,OAAO,CAAC+B,KAAK,CAAC,sBAAsB,EAAEZ,KAAK,CAACY,KAAK,CAAC;IACtD,CAAC;;IAED;IACAnC,aAAa,CAACqC,KAAK,CAAC,KAAK,CAAC,CAAC,CAAE;EACjC,CAAC,CAAC,OAAOF,KAAK,EAAE;IACZ/B,OAAO,CAAC+B,KAAK,CAAC,wBAAwB,EAAEA,KAAK,CAAC;EAClD;AACJ;AAEA,OAAO,SAASG,aAAaA,CAAA,EAAG;EAC5B,OAAO,IAAIC,OAAO,CAAC,CAACC,OAAO,EAAEC,MAAM,KAAK;IACpC,IAAIzC,aAAa,EAAE;MACf,IAAIA,aAAa,CAAC0C,KAAK,KAAK,UAAU,EAAE;QACpCtC,OAAO,CAACC,GAAG,CAAC,uBAAuB,CAAC;QACpCL,aAAa,CAAC2C,IAAI,CAAC,CAAC;QAEpB3C,aAAa,CAAC4B,MAAM,GAAG,YAAY;UAC/BxB,OAAO,CAACC,GAAG,CAAC,oBAAoB,CAAC;UACjC,MAAMwB,SAAS,GAAG,IAAIC,IAAI,CAAC5B,WAAW,EAAE;YAAE6B,IAAI,EAAE/B,aAAa,CAACmB,QAAQ,IAAI;UAAa,CAAC,CAAC;UAEzF,IAAIU,SAAS,CAACJ,IAAI,GAAG,CAAC,EAAE;YACpB,IAAI;cACA;cACA,MAAMO,iBAAiB,CAACH,SAAS,CAAC;;cAElC;cACA,IAAI5B,kBAAkB,IAAIA,kBAAkB,CAACgC,IAAI,CAAC,CAAC,KAAK,EAAE,EAAE;gBACxD7B,OAAO,CAACC,GAAG,CAAC,4BAA4B,EAAEJ,kBAAkB,CAAC;gBAC7DuC,OAAO,CAACvC,kBAAkB,CAAC,CAAC,CAAE;cAClC,CAAC,MAAM;gBACHG,OAAO,CAAC+B,KAAK,CAAC,oDAAoD,CAAC;gBACnEM,MAAM,CAAC,oDAAoD,CAAC;cAChE;YACJ,CAAC,CAAC,OAAON,KAAK,EAAE;cACZ/B,OAAO,CAAC+B,KAAK,CAAC,+BAA+B,EAAEA,KAAK,CAAC;cACrDM,MAAM,CAAC,+BAA+B,CAAC;YAC3C;UACJ,CAAC,MAAM;YACHrC,OAAO,CAAC+B,KAAK,CAAC,8CAA8C,CAAC;YAC7DM,MAAM,CAAC,sBAAsB,CAAC;UAClC;QACJ,CAAC;MACL,CAAC,MAAM;QACHrC,OAAO,CAAC+B,KAAK,CAAC,4BAA4B,CAAC;QAC3CM,MAAM,CAAC,4BAA4B,CAAC;MACxC;IACJ,CAAC,MAAM;MACHrC,OAAO,CAAC+B,KAAK,CAAC,kCAAkC,CAAC;MACjDM,MAAM,CAAC,kCAAkC,CAAC;IAC9C;EACJ,CAAC,CAAC;AACN;;AAKA;AACA,OAAO,eAAeT,iBAAiBA,CAACH,SAAS,EAAE;EAC/CzB,OAAO,CAACC,GAAG,CAAC,sCAAsC,CAAC;EACnD,MAAMuC,QAAQ,GAAG,IAAIC,QAAQ,CAAC,CAAC;EAC/BD,QAAQ,CAACE,MAAM,CAAC,OAAO,EAAEjB,SAAS,EAAE,gBAAgB,CAAC;EAErD,IAAI;IACA,MAAMkB,QAAQ,GAAG,MAAMC,KAAK,CAAC,kCAAkC,EAAE;MAC7DC,MAAM,EAAE,MAAM;MACdC,IAAI,EAAEN;IACV,CAAC,CAAC;IAEF,IAAI,CAACG,QAAQ,CAACI,EAAE,EAAE;MACd,MAAM,IAAIlC,KAAK,CAAC,iBAAiB8B,QAAQ,CAACK,MAAM,EAAE,CAAC;IACvD;IAEA,MAAMC,MAAM,GAAG,MAAMN,QAAQ,CAACO,IAAI,CAAC,CAAC;IACpClD,OAAO,CAACC,GAAG,CAAC,uBAAuB,EAAEgD,MAAM,CAAC;IAE5C,IAAIA,MAAM,IAAIA,MAAM,CAACE,aAAa,EAAE;MAChCtD,kBAAkB,IAAI,GAAG,GAAGoD,MAAM,CAACE,aAAa,CAACtB,IAAI,CAAC,CAAC,CAAC,CAAC;MACzD7B,OAAO,CAACC,GAAG,CAAC,sBAAsB,EAAEJ,kBAAkB,CAAC,CAAC,CAAC;IAC7D,CAAC,MAAM;MACHG,OAAO,CAAC+B,KAAK,CAAC,sCAAsC,EAAEkB,MAAM,CAAC;IACjE;EACJ,CAAC,CAAC,OAAOlB,KAAK,EAAE;IACZ/B,OAAO,CAAC+B,KAAK,CAAC,wBAAwB,EAAEA,KAAK,CAAC;EAClD;AACJ;;AAIA;AACA;AACA;AACA,OAAO,eAAeD,2BAA2BA,CAACjC,kBAAkB,EAAE;EAClE,IAAI,CAACA,kBAAkB,IAAIA,kBAAkB,CAACgC,IAAI,CAAC,CAAC,KAAK,EAAE,EAAE;IACzD7B,OAAO,CAAC+B,KAAK,CAAC,mCAAmC,CAAC;IAClD;EACJ;EAEA/B,OAAO,CAACC,GAAG,CAAC,qBAAqB,EAAEJ,kBAAkB,CAAC;EAEtD,IAAI;IACA,MAAM8C,QAAQ,GAAG,MAAMC,KAAK,CAAC,qCAAqC,EAAE;MAChEC,MAAM,EAAE,MAAM;MACdO,OAAO,EAAE;QACL,cAAc,EAAE;MACpB,CAAC;MACDN,IAAI,EAAEO,IAAI,CAACC,SAAS,CAAC;QAAEC,UAAU,EAAE1D;MAAmB,CAAC,CAAC,CAAG;IAC/D,CAAC,CAAC;IAEF,IAAI,CAAC8C,QAAQ,CAACI,EAAE,EAAE;MACd,MAAM,IAAIlC,KAAK,CAAC,iBAAiB8B,QAAQ,CAACK,MAAM,EAAE,CAAC;IACvD;IAEA,MAAMC,MAAM,GAAG,MAAMN,QAAQ,CAACO,IAAI,CAAC,CAAC;IACpClD,OAAO,CAACC,GAAG,CAAC,kBAAkB,EAAEgD,MAAM,CAACO,KAAK,CAAC;IAC7C,OAAOP,MAAM,CAACO,KAAK;EACvB,CAAC,CAAC,OAAOzB,KAAK,EAAE;IACZ/B,OAAO,CAAC+B,KAAK,CAAC,yBAAyB,EAAEA,KAAK,CAAC;EACnD;AACJ","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}