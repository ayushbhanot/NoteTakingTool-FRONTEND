{"ast":null,"code":"let isRecognitionRunning = false;\nlet finalTranscript = '';\nlet recognition;\nconst INTERIM_THRESHOLD = 100; // Set a character length threshold for interim transcript\nlet lastLoggedInterimTranscript = ''; // Store the last logged interim transcript to compare\n\nlet logCount = 0;\nfunction logWithLimit(message) {\n  logCount++;\n  if (logCount % 50 === 0) {\n    // Clear console after every 50 logs\n    console.clear();\n  }\n  console.log(message);\n}\n\n// Function to check WebkitSpeechRecognition support\nfunction checkSpeechRecognitionSupport() {\n  window.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n  if (!window.SpeechRecognition) {\n    logWithLimit('SpeechRecognition API not supported.');\n    alert('Your browser does not support speech recognition features.');\n    return false;\n  }\n  return true;\n}\n\n// Check for WebkitSpeechRecognition support early\nif (!checkSpeechRecognitionSupport()) {\n  alert('Your browser does not support the necessary speech recognition features.');\n}\n\n// Initialize WebkitSpeechRecognition\nfunction initializeRecognition() {\n  recognition = new window.SpeechRecognition();\n  recognition.continuous = true; // Allow continuous recognition\n  recognition.interimResults = true; // Capture partial results for real-time updates\n  recognition.lang = 'en-US'; // Set recognition language\n\n  // Handle recognition results (interim and final)\n  recognition.onresult = event => {\n    let interimTranscript = '';\n\n    // Iterate through results starting from the event.resultIndex\n    for (let i = event.resultIndex; i < event.results.length; i++) {\n      const result = event.results[i];\n\n      // If the result is final, append it to the final transcript\n      if (result.isFinal) {\n        finalTranscript += result[0].transcript; // Append to final transcript\n        logWithLimit('Final Transcript So Far: ' + finalTranscript); // Log final transcript\n      } else {\n        interimTranscript += result[0].transcript; // Append interim transcripts\n      }\n    }\n\n    // Check if the interim transcript is new and has changed significantly\n    if (interimTranscript !== lastLoggedInterimTranscript && interimTranscript.length >= INTERIM_THRESHOLD) {\n      finalTranscript += interimTranscript; // Append interim transcript to final transcript\n      lastLoggedInterimTranscript = interimTranscript; // Update last logged interim\n      logWithLimit('Appended Interim Transcript to Final: ' + finalTranscript);\n    }\n\n    // Log interim transcript only when it's new or updated\n    if (interimTranscript && interimTranscript !== lastLoggedInterimTranscript) {\n      logWithLimit('Updated Interim Transcript: ' + interimTranscript);\n    }\n  };\n\n  // Handle when recognition ends and restart if necessary (without sending transcript)\n  recognition.onend = () => {\n    logWithLimit('Speech recognition ended.');\n\n    // Only restart recognition if it wasn't stopped manually\n    if (isRecognitionRunning) {\n      logWithLimit('Restarting speech recognition...');\n      recognition.start(); // Automatically restart recognition\n    }\n  };\n\n  // Handle errors during recognition\n  recognition.onerror = event => {\n    logWithLimit('Speech Recognition Error: ' + event.error);\n    if (event.error === 'no-speech') {\n      alert('No speech detected. Please try again.');\n      setTimeout(() => {\n        startSpeechRecognition();\n      }, 1000); // Restart after 1 second if no speech is detected\n    }\n    if (event.error === 'audio-capture') {\n      alert('Please check your microphone permissions.');\n    }\n\n    // Handle other potential errors\n    if (event.error === 'aborted' || event.error === 'network') {\n      logWithLimit('Speech recognition was aborted or there was a network issue.');\n      recognition.start(); // Restart if it's a recoverable error\n    }\n  };\n}\n\n// Function to request microphone permission\nasync function requestMicPermission() {\n  try {\n    const stream = await navigator.mediaDevices.getUserMedia({\n      audio: true\n    });\n    logWithLimit('Microphone permission granted');\n    stream.getTracks().forEach(track => track.stop()); // Stop the stream immediately after permission is granted\n    return true;\n  } catch (error) {\n    logWithLimit('Microphone permission denied: ' + error);\n    alert('Microphone access is required for speech recognition.');\n    return false;\n  }\n}\n\n// Start speech recognition function\nexport async function startSpeechRecognition() {\n  const permissionGranted = await requestMicPermission(); // Ensure microphone permission is granted\n  if (!permissionGranted) return;\n  if (isRecognitionRunning) {\n    logWithLimit(\"Speech recognition is already running.\");\n    return;\n  }\n  finalTranscript = ''; // Clear the transcript at the start of a new session\n  initializeRecognition(); // Initialize the recognition instance\n  try {\n    recognition.start(); // Start speech recognition\n    isRecognitionRunning = true; // Mark recognition as running\n    logWithLimit('Speech recognition started.');\n  } catch (error) {\n    logWithLimit('Error starting speech recognition: ' + error);\n  }\n}\n\n// Stop speech recognition function (and send transcript)\nexport function stopSpeechRecognition() {\n  if (!isRecognitionRunning) {\n    logWithLimit(\"Speech recognition is not running.\");\n    return;\n  }\n  logWithLimit('Stopping speech recognition...');\n  recognition.stop(); // Stop recognition\n  isRecognitionRunning = false; // Mark recognition as stopped\n\n  // Send the final transcript to the backend for processing\n  if (finalTranscript) {\n    logWithLimit('Sending final transcript to backend.');\n    processTranscript(finalTranscript); // Send the complete transcript to the backend\n    finalTranscript = ''; // Clear the final transcript for the next session\n  }\n}\n\n// Process the final transcript and send to backend\nexport const processTranscript = async transcript => {\n  try {\n    // Send as JSON because the backend likely expects a JSON payload\n    const response = await fetch('http://localhost:3001/generateNotes', {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json'\n      },\n      body: JSON.stringify({\n        transcript\n      }) // Send the transcript as JSON\n    });\n    if (!response.ok) {\n      throw new Error(`Server error: ${response.status}`);\n    }\n    const result = await response.json();\n    logWithLimit('Generated notes: ' + JSON.stringify(result)); // Log the generated notes from the backend\n  } catch (error) {\n    logWithLimit('Error sending transcript to backend: ' + error); // Log errors that occur during the API call\n  }\n};","map":{"version":3,"names":["isRecognitionRunning","finalTranscript","recognition","INTERIM_THRESHOLD","lastLoggedInterimTranscript","logCount","logWithLimit","message","console","clear","log","checkSpeechRecognitionSupport","window","SpeechRecognition","webkitSpeechRecognition","alert","initializeRecognition","continuous","interimResults","lang","onresult","event","interimTranscript","i","resultIndex","results","length","result","isFinal","transcript","onend","start","onerror","error","setTimeout","startSpeechRecognition","requestMicPermission","stream","navigator","mediaDevices","getUserMedia","audio","getTracks","forEach","track","stop","permissionGranted","stopSpeechRecognition","processTranscript","response","fetch","method","headers","body","JSON","stringify","ok","Error","status","json"],"sources":["/Users/ayushbhanot/Documents/Coding/Riipen/AITranscriptionApp/aitranscriptionapp/src/services/audioRecording.js"],"sourcesContent":["let isRecognitionRunning = false;\nlet finalTranscript = ''; \nlet recognition;\nconst INTERIM_THRESHOLD = 100;  // Set a character length threshold for interim transcript\nlet lastLoggedInterimTranscript = '';  // Store the last logged interim transcript to compare\n\nlet logCount = 0;\n\nfunction logWithLimit(message) {\n    logCount++;\n\n    if (logCount % 50 === 0) {  // Clear console after every 50 logs\n        console.clear();\n    }\n\n    console.log(message);\n}\n\n// Function to check WebkitSpeechRecognition support\nfunction checkSpeechRecognitionSupport() {\n    window.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n    if (!window.SpeechRecognition) {\n        logWithLimit('SpeechRecognition API not supported.');\n        alert('Your browser does not support speech recognition features.');\n        return false;\n    }\n    return true;\n}\n\n// Check for WebkitSpeechRecognition support early\nif (!checkSpeechRecognitionSupport()) {\n    alert('Your browser does not support the necessary speech recognition features.');\n}\n\n// Initialize WebkitSpeechRecognition\nfunction initializeRecognition() {\n    recognition = new window.SpeechRecognition();\n    recognition.continuous = true;  // Allow continuous recognition\n    recognition.interimResults = true;  // Capture partial results for real-time updates\n    recognition.lang = 'en-US';  // Set recognition language\n\n    // Handle recognition results (interim and final)\n    recognition.onresult = (event) => {\n        let interimTranscript = '';\n\n        // Iterate through results starting from the event.resultIndex\n        for (let i = event.resultIndex; i < event.results.length; i++) {\n            const result = event.results[i];\n\n            // If the result is final, append it to the final transcript\n            if (result.isFinal) {\n                finalTranscript += result[0].transcript;  // Append to final transcript\n                logWithLimit('Final Transcript So Far: ' + finalTranscript);  // Log final transcript\n            } else {\n                interimTranscript += result[0].transcript;  // Append interim transcripts\n            }\n        }\n\n        // Check if the interim transcript is new and has changed significantly\n        if (interimTranscript !== lastLoggedInterimTranscript && interimTranscript.length >= INTERIM_THRESHOLD) {\n            finalTranscript += interimTranscript;  // Append interim transcript to final transcript\n            lastLoggedInterimTranscript = interimTranscript;  // Update last logged interim\n            logWithLimit('Appended Interim Transcript to Final: ' + finalTranscript);\n        }\n\n        // Log interim transcript only when it's new or updated\n        if (interimTranscript && interimTranscript !== lastLoggedInterimTranscript) {\n            logWithLimit('Updated Interim Transcript: ' + interimTranscript);\n        }\n    };\n\n    // Handle when recognition ends and restart if necessary (without sending transcript)\n    recognition.onend = () => {\n        logWithLimit('Speech recognition ended.');\n\n        // Only restart recognition if it wasn't stopped manually\n        if (isRecognitionRunning) {\n            logWithLimit('Restarting speech recognition...');\n            recognition.start();  // Automatically restart recognition\n        }\n    };\n\n    // Handle errors during recognition\n    recognition.onerror = (event) => {\n        logWithLimit('Speech Recognition Error: ' + event.error);\n    \n        if (event.error === 'no-speech') {\n            alert('No speech detected. Please try again.');\n            setTimeout(() => {\n                startSpeechRecognition();\n            }, 1000);  // Restart after 1 second if no speech is detected\n        }\n    \n        if (event.error === 'audio-capture') {\n            alert('Please check your microphone permissions.');\n        }\n    \n        // Handle other potential errors\n        if (event.error === 'aborted' || event.error === 'network') {\n            logWithLimit('Speech recognition was aborted or there was a network issue.');\n            recognition.start();  // Restart if it's a recoverable error\n        }\n    };\n}\n\n// Function to request microphone permission\nasync function requestMicPermission() {\n    try {\n        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n        logWithLimit('Microphone permission granted');\n        stream.getTracks().forEach(track => track.stop());  // Stop the stream immediately after permission is granted\n        return true;\n    } catch (error) {\n        logWithLimit('Microphone permission denied: ' + error);\n        alert('Microphone access is required for speech recognition.');\n        return false;\n    }\n}\n\n// Start speech recognition function\nexport async function startSpeechRecognition() {\n    const permissionGranted = await requestMicPermission();  // Ensure microphone permission is granted\n    if (!permissionGranted) return;\n\n    if (isRecognitionRunning) {\n        logWithLimit(\"Speech recognition is already running.\");\n        return;\n    }\n\n    finalTranscript = '';  // Clear the transcript at the start of a new session\n    initializeRecognition();  // Initialize the recognition instance\n    try {\n        recognition.start();  // Start speech recognition\n        isRecognitionRunning = true;  // Mark recognition as running\n        logWithLimit('Speech recognition started.');\n    } catch (error) {\n        logWithLimit('Error starting speech recognition: ' + error);\n    }\n}\n\n// Stop speech recognition function (and send transcript)\nexport function stopSpeechRecognition() {\n    if (!isRecognitionRunning) {\n        logWithLimit(\"Speech recognition is not running.\");\n        return;\n    }\n    logWithLimit('Stopping speech recognition...');\n    recognition.stop();  // Stop recognition\n    isRecognitionRunning = false;  // Mark recognition as stopped\n\n    // Send the final transcript to the backend for processing\n    if (finalTranscript) {\n        logWithLimit('Sending final transcript to backend.');\n        processTranscript(finalTranscript);  // Send the complete transcript to the backend\n        finalTranscript = '';  // Clear the final transcript for the next session\n    }\n}\n\n// Process the final transcript and send to backend\nexport const processTranscript = async (transcript) => {\n    try {\n        // Send as JSON because the backend likely expects a JSON payload\n        const response = await fetch('http://localhost:3001/generateNotes', {\n            method: 'POST',\n            headers: {\n                'Content-Type': 'application/json',\n            },\n            body: JSON.stringify({ transcript }),  // Send the transcript as JSON\n        });\n\n        if (!response.ok) {\n            throw new Error(`Server error: ${response.status}`);\n        }\n\n        const result = await response.json();\n        logWithLimit('Generated notes: ' + JSON.stringify(result));  // Log the generated notes from the backend\n    } catch (error) {\n        logWithLimit('Error sending transcript to backend: ' + error);  // Log errors that occur during the API call\n    }\n};\n"],"mappings":"AAAA,IAAIA,oBAAoB,GAAG,KAAK;AAChC,IAAIC,eAAe,GAAG,EAAE;AACxB,IAAIC,WAAW;AACf,MAAMC,iBAAiB,GAAG,GAAG,CAAC,CAAE;AAChC,IAAIC,2BAA2B,GAAG,EAAE,CAAC,CAAE;;AAEvC,IAAIC,QAAQ,GAAG,CAAC;AAEhB,SAASC,YAAYA,CAACC,OAAO,EAAE;EAC3BF,QAAQ,EAAE;EAEV,IAAIA,QAAQ,GAAG,EAAE,KAAK,CAAC,EAAE;IAAG;IACxBG,OAAO,CAACC,KAAK,CAAC,CAAC;EACnB;EAEAD,OAAO,CAACE,GAAG,CAACH,OAAO,CAAC;AACxB;;AAEA;AACA,SAASI,6BAA6BA,CAAA,EAAG;EACrCC,MAAM,CAACC,iBAAiB,GAAGD,MAAM,CAACC,iBAAiB,IAAID,MAAM,CAACE,uBAAuB;EACrF,IAAI,CAACF,MAAM,CAACC,iBAAiB,EAAE;IAC3BP,YAAY,CAAC,sCAAsC,CAAC;IACpDS,KAAK,CAAC,4DAA4D,CAAC;IACnE,OAAO,KAAK;EAChB;EACA,OAAO,IAAI;AACf;;AAEA;AACA,IAAI,CAACJ,6BAA6B,CAAC,CAAC,EAAE;EAClCI,KAAK,CAAC,0EAA0E,CAAC;AACrF;;AAEA;AACA,SAASC,qBAAqBA,CAAA,EAAG;EAC7Bd,WAAW,GAAG,IAAIU,MAAM,CAACC,iBAAiB,CAAC,CAAC;EAC5CX,WAAW,CAACe,UAAU,GAAG,IAAI,CAAC,CAAE;EAChCf,WAAW,CAACgB,cAAc,GAAG,IAAI,CAAC,CAAE;EACpChB,WAAW,CAACiB,IAAI,GAAG,OAAO,CAAC,CAAE;;EAE7B;EACAjB,WAAW,CAACkB,QAAQ,GAAIC,KAAK,IAAK;IAC9B,IAAIC,iBAAiB,GAAG,EAAE;;IAE1B;IACA,KAAK,IAAIC,CAAC,GAAGF,KAAK,CAACG,WAAW,EAAED,CAAC,GAAGF,KAAK,CAACI,OAAO,CAACC,MAAM,EAAEH,CAAC,EAAE,EAAE;MAC3D,MAAMI,MAAM,GAAGN,KAAK,CAACI,OAAO,CAACF,CAAC,CAAC;;MAE/B;MACA,IAAII,MAAM,CAACC,OAAO,EAAE;QAChB3B,eAAe,IAAI0B,MAAM,CAAC,CAAC,CAAC,CAACE,UAAU,CAAC,CAAE;QAC1CvB,YAAY,CAAC,2BAA2B,GAAGL,eAAe,CAAC,CAAC,CAAE;MAClE,CAAC,MAAM;QACHqB,iBAAiB,IAAIK,MAAM,CAAC,CAAC,CAAC,CAACE,UAAU,CAAC,CAAE;MAChD;IACJ;;IAEA;IACA,IAAIP,iBAAiB,KAAKlB,2BAA2B,IAAIkB,iBAAiB,CAACI,MAAM,IAAIvB,iBAAiB,EAAE;MACpGF,eAAe,IAAIqB,iBAAiB,CAAC,CAAE;MACvClB,2BAA2B,GAAGkB,iBAAiB,CAAC,CAAE;MAClDhB,YAAY,CAAC,wCAAwC,GAAGL,eAAe,CAAC;IAC5E;;IAEA;IACA,IAAIqB,iBAAiB,IAAIA,iBAAiB,KAAKlB,2BAA2B,EAAE;MACxEE,YAAY,CAAC,8BAA8B,GAAGgB,iBAAiB,CAAC;IACpE;EACJ,CAAC;;EAED;EACApB,WAAW,CAAC4B,KAAK,GAAG,MAAM;IACtBxB,YAAY,CAAC,2BAA2B,CAAC;;IAEzC;IACA,IAAIN,oBAAoB,EAAE;MACtBM,YAAY,CAAC,kCAAkC,CAAC;MAChDJ,WAAW,CAAC6B,KAAK,CAAC,CAAC,CAAC,CAAE;IAC1B;EACJ,CAAC;;EAED;EACA7B,WAAW,CAAC8B,OAAO,GAAIX,KAAK,IAAK;IAC7Bf,YAAY,CAAC,4BAA4B,GAAGe,KAAK,CAACY,KAAK,CAAC;IAExD,IAAIZ,KAAK,CAACY,KAAK,KAAK,WAAW,EAAE;MAC7BlB,KAAK,CAAC,uCAAuC,CAAC;MAC9CmB,UAAU,CAAC,MAAM;QACbC,sBAAsB,CAAC,CAAC;MAC5B,CAAC,EAAE,IAAI,CAAC,CAAC,CAAE;IACf;IAEA,IAAId,KAAK,CAACY,KAAK,KAAK,eAAe,EAAE;MACjClB,KAAK,CAAC,2CAA2C,CAAC;IACtD;;IAEA;IACA,IAAIM,KAAK,CAACY,KAAK,KAAK,SAAS,IAAIZ,KAAK,CAACY,KAAK,KAAK,SAAS,EAAE;MACxD3B,YAAY,CAAC,8DAA8D,CAAC;MAC5EJ,WAAW,CAAC6B,KAAK,CAAC,CAAC,CAAC,CAAE;IAC1B;EACJ,CAAC;AACL;;AAEA;AACA,eAAeK,oBAAoBA,CAAA,EAAG;EAClC,IAAI;IACA,MAAMC,MAAM,GAAG,MAAMC,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;MAAEC,KAAK,EAAE;IAAK,CAAC,CAAC;IACzEnC,YAAY,CAAC,+BAA+B,CAAC;IAC7C+B,MAAM,CAACK,SAAS,CAAC,CAAC,CAACC,OAAO,CAACC,KAAK,IAAIA,KAAK,CAACC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAE;IACpD,OAAO,IAAI;EACf,CAAC,CAAC,OAAOZ,KAAK,EAAE;IACZ3B,YAAY,CAAC,gCAAgC,GAAG2B,KAAK,CAAC;IACtDlB,KAAK,CAAC,uDAAuD,CAAC;IAC9D,OAAO,KAAK;EAChB;AACJ;;AAEA;AACA,OAAO,eAAeoB,sBAAsBA,CAAA,EAAG;EAC3C,MAAMW,iBAAiB,GAAG,MAAMV,oBAAoB,CAAC,CAAC,CAAC,CAAE;EACzD,IAAI,CAACU,iBAAiB,EAAE;EAExB,IAAI9C,oBAAoB,EAAE;IACtBM,YAAY,CAAC,wCAAwC,CAAC;IACtD;EACJ;EAEAL,eAAe,GAAG,EAAE,CAAC,CAAE;EACvBe,qBAAqB,CAAC,CAAC,CAAC,CAAE;EAC1B,IAAI;IACAd,WAAW,CAAC6B,KAAK,CAAC,CAAC,CAAC,CAAE;IACtB/B,oBAAoB,GAAG,IAAI,CAAC,CAAE;IAC9BM,YAAY,CAAC,6BAA6B,CAAC;EAC/C,CAAC,CAAC,OAAO2B,KAAK,EAAE;IACZ3B,YAAY,CAAC,qCAAqC,GAAG2B,KAAK,CAAC;EAC/D;AACJ;;AAEA;AACA,OAAO,SAASc,qBAAqBA,CAAA,EAAG;EACpC,IAAI,CAAC/C,oBAAoB,EAAE;IACvBM,YAAY,CAAC,oCAAoC,CAAC;IAClD;EACJ;EACAA,YAAY,CAAC,gCAAgC,CAAC;EAC9CJ,WAAW,CAAC2C,IAAI,CAAC,CAAC,CAAC,CAAE;EACrB7C,oBAAoB,GAAG,KAAK,CAAC,CAAE;;EAE/B;EACA,IAAIC,eAAe,EAAE;IACjBK,YAAY,CAAC,sCAAsC,CAAC;IACpD0C,iBAAiB,CAAC/C,eAAe,CAAC,CAAC,CAAE;IACrCA,eAAe,GAAG,EAAE,CAAC,CAAE;EAC3B;AACJ;;AAEA;AACA,OAAO,MAAM+C,iBAAiB,GAAG,MAAOnB,UAAU,IAAK;EACnD,IAAI;IACA;IACA,MAAMoB,QAAQ,GAAG,MAAMC,KAAK,CAAC,qCAAqC,EAAE;MAChEC,MAAM,EAAE,MAAM;MACdC,OAAO,EAAE;QACL,cAAc,EAAE;MACpB,CAAC;MACDC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;QAAE1B;MAAW,CAAC,CAAC,CAAG;IAC3C,CAAC,CAAC;IAEF,IAAI,CAACoB,QAAQ,CAACO,EAAE,EAAE;MACd,MAAM,IAAIC,KAAK,CAAC,iBAAiBR,QAAQ,CAACS,MAAM,EAAE,CAAC;IACvD;IAEA,MAAM/B,MAAM,GAAG,MAAMsB,QAAQ,CAACU,IAAI,CAAC,CAAC;IACpCrD,YAAY,CAAC,mBAAmB,GAAGgD,IAAI,CAACC,SAAS,CAAC5B,MAAM,CAAC,CAAC,CAAC,CAAE;EACjE,CAAC,CAAC,OAAOM,KAAK,EAAE;IACZ3B,YAAY,CAAC,uCAAuC,GAAG2B,KAAK,CAAC,CAAC,CAAE;EACpE;AACJ,CAAC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}