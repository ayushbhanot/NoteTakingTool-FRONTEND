{"ast":null,"code":"// let mediaRecorder = null; // Declare globally (commented out, we won't use MediaRecorder)\n// Function to check WebkitSpeechRecognition support\n/*function checkSpeechRecognitionSupport() {\n    window.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n    if (!window.SpeechRecognition) {\n        console.error('SpeechRecognition API not supported.');\n        alert('Your browser does not support speech recognition features.');\n        return false;\n    }\n    return true;\n}\n\n// Check for WebkitSpeechRecognition support early\nif (!checkSpeechRecognitionSupport()) {\n    alert('Your browser does not support the necessary speech recognition features.');\n}\n\n// Initialize WebkitSpeechRecognition\nconst recognition = new window.SpeechRecognition();\nrecognition.continuous = true;\nrecognition.interimResults = true; // Set to true to capture partial results\nrecognition.lang = 'en-US';\nlet isRecognitionRunning = false;\nlet finalTranscript = '';  // Store final transcript globally\n\n// Function to request microphone permission\nasync function requestMicPermission() {\n    try {\n        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n        console.log('Microphone permission granted');\n        stream.getTracks().forEach(track => track.stop());  // Stop the stream immediately\n        return true;\n    } catch (error) {\n        console.error('Microphone permission denied:', error);\n        alert('Microphone access is required for speech recognition.');\n        return false;\n    }\n}\n\n// Start speech recognition function\nexport async function startSpeechRecognition() {\n    const permissionGranted = await requestMicPermission();  // Ensure permission is granted\n    if (!permissionGranted) return;\n\n    if (isRecognitionRunning) {\n        console.error(\"Speech recognition is already running.\");\n        return;\n    }\n    try {\n        finalTranscript = '';  // Clear transcript on new session\n        recognition.start();\n        isRecognitionRunning = true;\n        console.log('Speech recognition started.');\n    } catch (error) {\n        console.error('Error starting speech recognition:', error);\n    }\n}\n\n// Stop speech recognition function\nexport function stopSpeechRecognition() {\n    if (!isRecognitionRunning) {\n        console.error(\"Speech recognition is not running.\");\n        return;\n    }\n    console.log('Stopping speech recognition...');\n    recognition.stop();\n}\n\n// Handle when recognition ends\nrecognition.onend = () => {\n    isRecognitionRunning = false;\n    console.log('Speech recognition stopped.');\n    \n    // Send the final transcript to backend for transcription when stopped\n    if (finalTranscript) {\n        processTranscript(finalTranscript);  // Send final transcript to backend\n    } else {\n        console.error(\"No transcript available to send.\");\n    }\n};\n\n// Handle when recognition is aborted\nrecognition.onabort = (event) => {\n    console.error('Speech recognition was aborted:', event);\n    // Optionally, restart recognition if needed\n    setTimeout(() => {\n        console.log('Attempting to restart speech recognition...');\n        startSpeechRecognition();\n    }, 1000);  // Delay to prevent immediate restart\n};\n\n// Process the transcript and send to backend\n// Process the transcript and send to backend\nexport const processTranscript = async (transcript) => {\n    try {\n        // Send as JSON, not FormData, because the backend likely expects a JSON payload\n        const response = await fetch('http://localhost:3001/generateNotes', {\n            method: 'POST',\n            headers: {\n                'Content-Type': 'application/json',\n            },\n            body: JSON.stringify({ transcript }),  // Send the transcript as JSON\n        });\n\n        if (!response.ok) {\n            throw new Error(`Server error: ${response.status}`);\n        }\n\n        const result = await response.json();\n        console.log('Generated notes:', result);\n    } catch (error) {\n        console.error('Error sending transcript to backend:', error);\n    }\n};\n\n\n// Event handler for when recognition results are available\nrecognition.onresult = (event) => {\n    let interimTranscript = '';\n\n    for (let i = event.resultIndex; i < event.results.length; i++) {\n        const result = event.results[i];\n        if (result.isFinal) {\n            finalTranscript += result[0].transcript;\n        } else {\n            interimTranscript += result[0].transcript;\n        }\n    }\n\n    console.log('Interim Transcript:', interimTranscript);\n    console.log('Final Transcript:', finalTranscript);  // Only append the final result once\n};\n\nrecognition.onerror = (event) => {\n    console.error('Speech Recognition Error:', event.error);\n\n    // Handle specific \"no-speech\" error\n    if (event.error === 'no-speech') {\n        console.log('No speech detected. Please try speaking more clearly.');\n        alert('No speech detected. Please try again.');\n        // Optionally, restart the recognition\n        setTimeout(() => {\n            console.log('Restarting speech recognition after no-speech error...');\n            startSpeechRecognition();\n        }, 1000);  // Delay before restarting\n    }\n\n    if (event.error === 'audio-capture') {\n        console.error('Microphone access issue.');\n        alert('Please check your microphone permissions.');\n    }\n};\nrecognition.onabort = (event) => {\n    console.error('Speech recognition was aborted:', event);\n    // Optionally restart recognition\n    setTimeout(() => {\n        console.log('Attempting to restart speech recognition...');\n        startSpeechRecognition();\n    }, 1000);  // Delay to prevent immediate restart\n};\n*/// COMMENTED OUT MEDIARECORDER CODE\nlet mediaRecorder=null;// Declare MediaRecorder globally\nlet combinedTranscript=\"\";// String to hold combined transcript\nlet audioChunks=[];// Store audio chunks\nexport async function startRecording(){console.log('Attempting to start recording...');combinedTranscript=\"\";// Reset combined transcript on new recording\ntry{const micStream=await navigator.mediaDevices.getUserMedia({audio:{echoCancellation:false,noiseSuppression:false,sampleRate:44100}});console.log('Microphone stream acquired:',micStream);const combinedStream=micStream;console.log('Combined stream:',combinedStream);if(combinedStream.getAudioTracks().length===0){throw new Error('Combined stream has no audio tracks.');}let options={mimeType:'audio/webm; codecs=opus'};if(!MediaRecorder.isTypeSupported(options.mimeType)){options={mimeType:'audio/webm'};}if(!MediaRecorder.isTypeSupported(options.mimeType)){options={mimeType:'audio/mp4'};}if(!MediaRecorder.isTypeSupported(options.mimeType)){options={};}mediaRecorder=new MediaRecorder(combinedStream,options);console.log('MediaRecorder initialized:',mediaRecorder);// Clear audio chunks before starting a new recording\naudioChunks=[];mediaRecorder.ondataavailable=event=>{if(event.data.size>0){audioChunks.push(event.data);// Store each chunk\nconsole.log('Audio chunk available:',event.data);}};mediaRecorder.onstart=()=>{console.log('Recording started.');};mediaRecorder.onstop=async()=>{console.log('Recording stopped.');const audioBlob=new Blob(audioChunks,{type:options.mimeType||'audio/webm'});console.log('Audio Blob size:',audioBlob.size);if(audioBlob.size>0){await processAudioChunk(audioBlob);// Process the final audio blob at the end of recording\n}else{console.error('Audio Blob is empty, not sending to backend');}// Now that recording is stopped, trigger the note generation\nawait generateNotesFromTranscript();// Generate notes from the combined transcript\n};mediaRecorder.onerror=event=>{console.error('MediaRecorder error:',event.error);};// Start recording with a timeslice of 30 seconds (30000 ms) to generate chunks every 30 seconds\nmediaRecorder.start(30000);// Collect blobs every 30 seconds\n}catch(error){console.error('Error capturing audio:',error);}}export function stopRecording(){if(mediaRecorder){if(mediaRecorder.state!=='inactive'){console.log('Stopping recording...');mediaRecorder.stop();}else{console.error('MediaRecorder is inactive.');}}else{console.error('No MediaRecorder instance found.');}}// Process the recorded audio chunk and send it to the backend for transcription\nexport async function processAudioChunk(audioBlob){console.log('Processing audio chunk for upload...');const formData=new FormData();formData.append('audio',audioBlob,'recording.webm');try{const response=await fetch('http://localhost:3001/transcribe',{method:'POST',body:formData});if(!response.ok){throw new Error(`Server error: ${response.status}`);}const result=await response.json();console.log('Transcription result:',result);if(result&&result.transcription){combinedTranscript+=\" \"+result.transcription.trim();// Append transcription\nconsole.log('Combined transcript:',combinedTranscript);// Add this line to log the combined transcript\n}else{console.error('Transcription is empty or undefined:',result);}}catch(error){console.error('Error uploading audio:',error);}}// Function to send the combined transcript to the backend for note generation\n// Ensure `setGeneratedNotes` is properly passed as a prop or available in scope\n// Function to send the combined transcript to the backend for note generation\nexport async function generateNotesFromTranscript(transcript){if(!transcript||transcript.trim()===\"\"){console.error('Transcript is undefined or empty.');return;}try{const response=await fetch('http://localhost:3001/generateNotes',{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify({transcript})// Send the transcript to the backend\n});if(!response.ok){throw new Error(`Server error: ${response.status}`);}const result=await response.json();console.log('Generated notes from backend:',result.notes);return result.notes;// Return the organized notes from the backend\n}catch(error){console.error('Error generating notes:',error);}}","map":{"version":3,"names":["mediaRecorder","combinedTranscript","audioChunks","startRecording","console","log","micStream","navigator","mediaDevices","getUserMedia","audio","echoCancellation","noiseSuppression","sampleRate","combinedStream","getAudioTracks","length","Error","options","mimeType","MediaRecorder","isTypeSupported","ondataavailable","event","data","size","push","onstart","onstop","audioBlob","Blob","type","processAudioChunk","error","generateNotesFromTranscript","onerror","start","stopRecording","state","stop","formData","FormData","append","response","fetch","method","body","ok","status","result","json","transcription","trim","transcript","headers","JSON","stringify","notes"],"sources":["/Users/ayushbhanot/Documents/Coding/Riipen/AITranscriptionApp/aitranscriptionapp/src/services/audioRecording.js"],"sourcesContent":["// let mediaRecorder = null; // Declare globally (commented out, we won't use MediaRecorder)\n\n// Function to check WebkitSpeechRecognition support\n/*function checkSpeechRecognitionSupport() {\n    window.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n    if (!window.SpeechRecognition) {\n        console.error('SpeechRecognition API not supported.');\n        alert('Your browser does not support speech recognition features.');\n        return false;\n    }\n    return true;\n}\n\n// Check for WebkitSpeechRecognition support early\nif (!checkSpeechRecognitionSupport()) {\n    alert('Your browser does not support the necessary speech recognition features.');\n}\n\n// Initialize WebkitSpeechRecognition\nconst recognition = new window.SpeechRecognition();\nrecognition.continuous = true;\nrecognition.interimResults = true; // Set to true to capture partial results\nrecognition.lang = 'en-US';\nlet isRecognitionRunning = false;\nlet finalTranscript = '';  // Store final transcript globally\n\n// Function to request microphone permission\nasync function requestMicPermission() {\n    try {\n        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n        console.log('Microphone permission granted');\n        stream.getTracks().forEach(track => track.stop());  // Stop the stream immediately\n        return true;\n    } catch (error) {\n        console.error('Microphone permission denied:', error);\n        alert('Microphone access is required for speech recognition.');\n        return false;\n    }\n}\n\n// Start speech recognition function\nexport async function startSpeechRecognition() {\n    const permissionGranted = await requestMicPermission();  // Ensure permission is granted\n    if (!permissionGranted) return;\n\n    if (isRecognitionRunning) {\n        console.error(\"Speech recognition is already running.\");\n        return;\n    }\n    try {\n        finalTranscript = '';  // Clear transcript on new session\n        recognition.start();\n        isRecognitionRunning = true;\n        console.log('Speech recognition started.');\n    } catch (error) {\n        console.error('Error starting speech recognition:', error);\n    }\n}\n\n// Stop speech recognition function\nexport function stopSpeechRecognition() {\n    if (!isRecognitionRunning) {\n        console.error(\"Speech recognition is not running.\");\n        return;\n    }\n    console.log('Stopping speech recognition...');\n    recognition.stop();\n}\n\n// Handle when recognition ends\nrecognition.onend = () => {\n    isRecognitionRunning = false;\n    console.log('Speech recognition stopped.');\n    \n    // Send the final transcript to backend for transcription when stopped\n    if (finalTranscript) {\n        processTranscript(finalTranscript);  // Send final transcript to backend\n    } else {\n        console.error(\"No transcript available to send.\");\n    }\n};\n\n// Handle when recognition is aborted\nrecognition.onabort = (event) => {\n    console.error('Speech recognition was aborted:', event);\n    // Optionally, restart recognition if needed\n    setTimeout(() => {\n        console.log('Attempting to restart speech recognition...');\n        startSpeechRecognition();\n    }, 1000);  // Delay to prevent immediate restart\n};\n\n// Process the transcript and send to backend\n// Process the transcript and send to backend\nexport const processTranscript = async (transcript) => {\n    try {\n        // Send as JSON, not FormData, because the backend likely expects a JSON payload\n        const response = await fetch('http://localhost:3001/generateNotes', {\n            method: 'POST',\n            headers: {\n                'Content-Type': 'application/json',\n            },\n            body: JSON.stringify({ transcript }),  // Send the transcript as JSON\n        });\n\n        if (!response.ok) {\n            throw new Error(`Server error: ${response.status}`);\n        }\n\n        const result = await response.json();\n        console.log('Generated notes:', result);\n    } catch (error) {\n        console.error('Error sending transcript to backend:', error);\n    }\n};\n\n\n// Event handler for when recognition results are available\nrecognition.onresult = (event) => {\n    let interimTranscript = '';\n\n    for (let i = event.resultIndex; i < event.results.length; i++) {\n        const result = event.results[i];\n        if (result.isFinal) {\n            finalTranscript += result[0].transcript;\n        } else {\n            interimTranscript += result[0].transcript;\n        }\n    }\n\n    console.log('Interim Transcript:', interimTranscript);\n    console.log('Final Transcript:', finalTranscript);  // Only append the final result once\n};\n\nrecognition.onerror = (event) => {\n    console.error('Speech Recognition Error:', event.error);\n\n    // Handle specific \"no-speech\" error\n    if (event.error === 'no-speech') {\n        console.log('No speech detected. Please try speaking more clearly.');\n        alert('No speech detected. Please try again.');\n        // Optionally, restart the recognition\n        setTimeout(() => {\n            console.log('Restarting speech recognition after no-speech error...');\n            startSpeechRecognition();\n        }, 1000);  // Delay before restarting\n    }\n\n    if (event.error === 'audio-capture') {\n        console.error('Microphone access issue.');\n        alert('Please check your microphone permissions.');\n    }\n};\nrecognition.onabort = (event) => {\n    console.error('Speech recognition was aborted:', event);\n    // Optionally restart recognition\n    setTimeout(() => {\n        console.log('Attempting to restart speech recognition...');\n        startSpeechRecognition();\n    }, 1000);  // Delay to prevent immediate restart\n};\n*/\n\n// COMMENTED OUT MEDIARECORDER CODE\n\nlet mediaRecorder = null; // Declare MediaRecorder globally\nlet combinedTranscript = \"\"; // String to hold combined transcript\nlet audioChunks = []; // Store audio chunks\n\n\nexport async function startRecording() {\n    console.log('Attempting to start recording...');\n    combinedTranscript = \"\";  // Reset combined transcript on new recording\n    try {\n        const micStream = await navigator.mediaDevices.getUserMedia({\n            audio: {\n                echoCancellation: false,\n                noiseSuppression: false,\n                sampleRate: 44100\n            }\n        });\n        console.log('Microphone stream acquired:', micStream);\n\n        const combinedStream = micStream;\n        console.log('Combined stream:', combinedStream);\n\n        if (combinedStream.getAudioTracks().length === 0) {\n            throw new Error('Combined stream has no audio tracks.');\n        }\n\n        let options = { mimeType: 'audio/webm; codecs=opus' };\n        if (!MediaRecorder.isTypeSupported(options.mimeType)) {\n            options = { mimeType: 'audio/webm' };\n        }\n        if (!MediaRecorder.isTypeSupported(options.mimeType)) {\n            options = { mimeType: 'audio/mp4' };\n        }\n        if (!MediaRecorder.isTypeSupported(options.mimeType)) {\n            options = {};\n        }\n\n        mediaRecorder = new MediaRecorder(combinedStream, options);\n        console.log('MediaRecorder initialized:', mediaRecorder);\n\n        // Clear audio chunks before starting a new recording\n        audioChunks = [];\n\n        mediaRecorder.ondataavailable = (event) => {\n            if (event.data.size > 0) {\n                audioChunks.push(event.data); // Store each chunk\n                console.log('Audio chunk available:', event.data);\n            }\n        };\n\n        mediaRecorder.onstart = () => {\n            console.log('Recording started.');\n        };\n\n        mediaRecorder.onstop = async () => {\n            console.log('Recording stopped.');\n            const audioBlob = new Blob(audioChunks, { type: options.mimeType || 'audio/webm' });\n            console.log('Audio Blob size:', audioBlob.size);\n\n            if (audioBlob.size > 0) {\n                await processAudioChunk(audioBlob);  // Process the final audio blob at the end of recording\n            } else {\n                console.error('Audio Blob is empty, not sending to backend');\n            }\n\n            // Now that recording is stopped, trigger the note generation\n            await generateNotesFromTranscript();  // Generate notes from the combined transcript\n        };\n\n        mediaRecorder.onerror = (event) => {\n            console.error('MediaRecorder error:', event.error);\n        };\n\n        // Start recording with a timeslice of 30 seconds (30000 ms) to generate chunks every 30 seconds\n        mediaRecorder.start(30000);  // Collect blobs every 30 seconds\n    } catch (error) {\n        console.error('Error capturing audio:', error);\n    }\n}\n\nexport function stopRecording() {\n    if (mediaRecorder) {\n        if (mediaRecorder.state !== 'inactive') {\n            console.log('Stopping recording...');\n            mediaRecorder.stop();\n        } else {\n            console.error('MediaRecorder is inactive.');\n        }\n    } else {\n        console.error('No MediaRecorder instance found.');\n    }\n}\n\n// Process the recorded audio chunk and send it to the backend for transcription\nexport async function processAudioChunk(audioBlob) {\n    console.log('Processing audio chunk for upload...');\n    const formData = new FormData();\n    formData.append('audio', audioBlob, 'recording.webm');\n\n    try {\n        const response = await fetch('http://localhost:3001/transcribe', {\n            method: 'POST',\n            body: formData,\n        });\n\n        if (!response.ok) {\n            throw new Error(`Server error: ${response.status}`);\n        }\n\n        const result = await response.json();\n        console.log('Transcription result:', result);\n\n        if (result && result.transcription) {\n            combinedTranscript += \" \" + result.transcription.trim(); // Append transcription\n            console.log('Combined transcript:', combinedTranscript); // Add this line to log the combined transcript\n        } else {\n            console.error('Transcription is empty or undefined:', result);\n        }\n    } catch (error) {\n        console.error('Error uploading audio:', error);\n    }\n}\n\n\n\n// Function to send the combined transcript to the backend for note generation\n// Ensure `setGeneratedNotes` is properly passed as a prop or available in scope\n// Function to send the combined transcript to the backend for note generation\nexport async function generateNotesFromTranscript(transcript) {\n    if (!transcript || transcript.trim() === \"\") {\n        console.error('Transcript is undefined or empty.');\n        return;\n    }\n\n    try {\n        const response = await fetch('http://localhost:3001/generateNotes', {\n            method: 'POST',\n            headers: {\n                'Content-Type': 'application/json',\n            },\n            body: JSON.stringify({ transcript }),  // Send the transcript to the backend\n        });\n\n        if (!response.ok) {\n            throw new Error(`Server error: ${response.status}`);\n        }\n\n        const result = await response.json();\n        console.log('Generated notes from backend:', result.notes);\n        return result.notes;  // Return the organized notes from the backend\n    } catch (error) {\n        console.error('Error generating notes:', error);\n    }\n}\n\n\n"],"mappings":"AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,EAEA;AAEA,GAAI,CAAAA,aAAa,CAAG,IAAI,CAAE;AAC1B,GAAI,CAAAC,kBAAkB,CAAG,EAAE,CAAE;AAC7B,GAAI,CAAAC,WAAW,CAAG,EAAE,CAAE;AAGtB,MAAO,eAAe,CAAAC,cAAcA,CAAA,CAAG,CACnCC,OAAO,CAACC,GAAG,CAAC,kCAAkC,CAAC,CAC/CJ,kBAAkB,CAAG,EAAE,CAAG;AAC1B,GAAI,CACA,KAAM,CAAAK,SAAS,CAAG,KAAM,CAAAC,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC,CACxDC,KAAK,CAAE,CACHC,gBAAgB,CAAE,KAAK,CACvBC,gBAAgB,CAAE,KAAK,CACvBC,UAAU,CAAE,KAChB,CACJ,CAAC,CAAC,CACFT,OAAO,CAACC,GAAG,CAAC,6BAA6B,CAAEC,SAAS,CAAC,CAErD,KAAM,CAAAQ,cAAc,CAAGR,SAAS,CAChCF,OAAO,CAACC,GAAG,CAAC,kBAAkB,CAAES,cAAc,CAAC,CAE/C,GAAIA,cAAc,CAACC,cAAc,CAAC,CAAC,CAACC,MAAM,GAAK,CAAC,CAAE,CAC9C,KAAM,IAAI,CAAAC,KAAK,CAAC,sCAAsC,CAAC,CAC3D,CAEA,GAAI,CAAAC,OAAO,CAAG,CAAEC,QAAQ,CAAE,yBAA0B,CAAC,CACrD,GAAI,CAACC,aAAa,CAACC,eAAe,CAACH,OAAO,CAACC,QAAQ,CAAC,CAAE,CAClDD,OAAO,CAAG,CAAEC,QAAQ,CAAE,YAAa,CAAC,CACxC,CACA,GAAI,CAACC,aAAa,CAACC,eAAe,CAACH,OAAO,CAACC,QAAQ,CAAC,CAAE,CAClDD,OAAO,CAAG,CAAEC,QAAQ,CAAE,WAAY,CAAC,CACvC,CACA,GAAI,CAACC,aAAa,CAACC,eAAe,CAACH,OAAO,CAACC,QAAQ,CAAC,CAAE,CAClDD,OAAO,CAAG,CAAC,CAAC,CAChB,CAEAlB,aAAa,CAAG,GAAI,CAAAoB,aAAa,CAACN,cAAc,CAAEI,OAAO,CAAC,CAC1Dd,OAAO,CAACC,GAAG,CAAC,4BAA4B,CAAEL,aAAa,CAAC,CAExD;AACAE,WAAW,CAAG,EAAE,CAEhBF,aAAa,CAACsB,eAAe,CAAIC,KAAK,EAAK,CACvC,GAAIA,KAAK,CAACC,IAAI,CAACC,IAAI,CAAG,CAAC,CAAE,CACrBvB,WAAW,CAACwB,IAAI,CAACH,KAAK,CAACC,IAAI,CAAC,CAAE;AAC9BpB,OAAO,CAACC,GAAG,CAAC,wBAAwB,CAAEkB,KAAK,CAACC,IAAI,CAAC,CACrD,CACJ,CAAC,CAEDxB,aAAa,CAAC2B,OAAO,CAAG,IAAM,CAC1BvB,OAAO,CAACC,GAAG,CAAC,oBAAoB,CAAC,CACrC,CAAC,CAEDL,aAAa,CAAC4B,MAAM,CAAG,SAAY,CAC/BxB,OAAO,CAACC,GAAG,CAAC,oBAAoB,CAAC,CACjC,KAAM,CAAAwB,SAAS,CAAG,GAAI,CAAAC,IAAI,CAAC5B,WAAW,CAAE,CAAE6B,IAAI,CAAEb,OAAO,CAACC,QAAQ,EAAI,YAAa,CAAC,CAAC,CACnFf,OAAO,CAACC,GAAG,CAAC,kBAAkB,CAAEwB,SAAS,CAACJ,IAAI,CAAC,CAE/C,GAAII,SAAS,CAACJ,IAAI,CAAG,CAAC,CAAE,CACpB,KAAM,CAAAO,iBAAiB,CAACH,SAAS,CAAC,CAAG;AACzC,CAAC,IAAM,CACHzB,OAAO,CAAC6B,KAAK,CAAC,6CAA6C,CAAC,CAChE,CAEA;AACA,KAAM,CAAAC,2BAA2B,CAAC,CAAC,CAAG;AAC1C,CAAC,CAEDlC,aAAa,CAACmC,OAAO,CAAIZ,KAAK,EAAK,CAC/BnB,OAAO,CAAC6B,KAAK,CAAC,sBAAsB,CAAEV,KAAK,CAACU,KAAK,CAAC,CACtD,CAAC,CAED;AACAjC,aAAa,CAACoC,KAAK,CAAC,KAAK,CAAC,CAAG;AACjC,CAAE,MAAOH,KAAK,CAAE,CACZ7B,OAAO,CAAC6B,KAAK,CAAC,wBAAwB,CAAEA,KAAK,CAAC,CAClD,CACJ,CAEA,MAAO,SAAS,CAAAI,aAAaA,CAAA,CAAG,CAC5B,GAAIrC,aAAa,CAAE,CACf,GAAIA,aAAa,CAACsC,KAAK,GAAK,UAAU,CAAE,CACpClC,OAAO,CAACC,GAAG,CAAC,uBAAuB,CAAC,CACpCL,aAAa,CAACuC,IAAI,CAAC,CAAC,CACxB,CAAC,IAAM,CACHnC,OAAO,CAAC6B,KAAK,CAAC,4BAA4B,CAAC,CAC/C,CACJ,CAAC,IAAM,CACH7B,OAAO,CAAC6B,KAAK,CAAC,kCAAkC,CAAC,CACrD,CACJ,CAEA;AACA,MAAO,eAAe,CAAAD,iBAAiBA,CAACH,SAAS,CAAE,CAC/CzB,OAAO,CAACC,GAAG,CAAC,sCAAsC,CAAC,CACnD,KAAM,CAAAmC,QAAQ,CAAG,GAAI,CAAAC,QAAQ,CAAC,CAAC,CAC/BD,QAAQ,CAACE,MAAM,CAAC,OAAO,CAAEb,SAAS,CAAE,gBAAgB,CAAC,CAErD,GAAI,CACA,KAAM,CAAAc,QAAQ,CAAG,KAAM,CAAAC,KAAK,CAAC,kCAAkC,CAAE,CAC7DC,MAAM,CAAE,MAAM,CACdC,IAAI,CAAEN,QACV,CAAC,CAAC,CAEF,GAAI,CAACG,QAAQ,CAACI,EAAE,CAAE,CACd,KAAM,IAAI,CAAA9B,KAAK,CAAC,iBAAiB0B,QAAQ,CAACK,MAAM,EAAE,CAAC,CACvD,CAEA,KAAM,CAAAC,MAAM,CAAG,KAAM,CAAAN,QAAQ,CAACO,IAAI,CAAC,CAAC,CACpC9C,OAAO,CAACC,GAAG,CAAC,uBAAuB,CAAE4C,MAAM,CAAC,CAE5C,GAAIA,MAAM,EAAIA,MAAM,CAACE,aAAa,CAAE,CAChClD,kBAAkB,EAAI,GAAG,CAAGgD,MAAM,CAACE,aAAa,CAACC,IAAI,CAAC,CAAC,CAAE;AACzDhD,OAAO,CAACC,GAAG,CAAC,sBAAsB,CAAEJ,kBAAkB,CAAC,CAAE;AAC7D,CAAC,IAAM,CACHG,OAAO,CAAC6B,KAAK,CAAC,sCAAsC,CAAEgB,MAAM,CAAC,CACjE,CACJ,CAAE,MAAOhB,KAAK,CAAE,CACZ7B,OAAO,CAAC6B,KAAK,CAAC,wBAAwB,CAAEA,KAAK,CAAC,CAClD,CACJ,CAIA;AACA;AACA;AACA,MAAO,eAAe,CAAAC,2BAA2BA,CAACmB,UAAU,CAAE,CAC1D,GAAI,CAACA,UAAU,EAAIA,UAAU,CAACD,IAAI,CAAC,CAAC,GAAK,EAAE,CAAE,CACzChD,OAAO,CAAC6B,KAAK,CAAC,mCAAmC,CAAC,CAClD,OACJ,CAEA,GAAI,CACA,KAAM,CAAAU,QAAQ,CAAG,KAAM,CAAAC,KAAK,CAAC,qCAAqC,CAAE,CAChEC,MAAM,CAAE,MAAM,CACdS,OAAO,CAAE,CACL,cAAc,CAAE,kBACpB,CAAC,CACDR,IAAI,CAAES,IAAI,CAACC,SAAS,CAAC,CAAEH,UAAW,CAAC,CAAI;AAC3C,CAAC,CAAC,CAEF,GAAI,CAACV,QAAQ,CAACI,EAAE,CAAE,CACd,KAAM,IAAI,CAAA9B,KAAK,CAAC,iBAAiB0B,QAAQ,CAACK,MAAM,EAAE,CAAC,CACvD,CAEA,KAAM,CAAAC,MAAM,CAAG,KAAM,CAAAN,QAAQ,CAACO,IAAI,CAAC,CAAC,CACpC9C,OAAO,CAACC,GAAG,CAAC,+BAA+B,CAAE4C,MAAM,CAACQ,KAAK,CAAC,CAC1D,MAAO,CAAAR,MAAM,CAACQ,KAAK,CAAG;AAC1B,CAAE,MAAOxB,KAAK,CAAE,CACZ7B,OAAO,CAAC6B,KAAK,CAAC,yBAAyB,CAAEA,KAAK,CAAC,CACnD,CACJ","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}