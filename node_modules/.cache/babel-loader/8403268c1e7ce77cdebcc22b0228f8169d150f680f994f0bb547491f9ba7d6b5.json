{"ast":null,"code":"let isRecognitionRunning = false;\nlet finalTranscript = '';\nlet recognition;\nconst INTERIM_THRESHOLD = 100; // Set a character length threshold for interim transcript\nlet lastLoggedInterimTranscript = ''; // Store the last logged interim transcript to compare\n\nlet logCount = 0;\nfunction logWithLimit(message) {\n  logCount++;\n  if (logCount % 50 === 0) {\n    // Clear console after every 100 logs\n    console.clear();\n  }\n  console.log(message);\n}\n\n// Function to check WebkitSpeechRecognition support\nfunction checkSpeechRecognitionSupport() {\n  window.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n  if (!window.SpeechRecognition) {\n    console.error('SpeechRecognition API not supported.');\n    alert('Your browser does not support speech recognition features.');\n    return false;\n  }\n  return true;\n}\n\n// Check for WebkitSpeechRecognition support early\nif (!checkSpeechRecognitionSupport()) {\n  alert('Your browser does not support the necessary speech recognition features.');\n}\n\n// Initialize WebkitSpeechRecognition\nfunction initializeRecognition() {\n  recognition = new window.SpeechRecognition();\n  recognition.continuous = true; // Allow continuous recognition\n  recognition.interimResults = true; // Capture partial results for real-time updates\n  recognition.lang = 'en-US'; // Set recognition language\n\n  // Handle recognition results (interim and final)\n  recognition.onresult = event => {\n    let interimTranscript = '';\n\n    // Iterate through results starting from the event.resultIndex\n    for (let i = event.resultIndex; i < event.results.length; i++) {\n      const result = event.results[i];\n\n      // If the result is final, append it to the final transcript\n      if (result.isFinal) {\n        finalTranscript += result[0].transcript; // Append to final transcript\n        console.log('Final Transcript So Far:', finalTranscript); // Log final transcript\n      } else {\n        interimTranscript += result[0].transcript; // Append interim transcripts\n      }\n    }\n\n    // Check if the interim transcript is new and has changed significantly\n    if (interimTranscript !== lastLoggedInterimTranscript && interimTranscript.length >= INTERIM_THRESHOLD) {\n      finalTranscript += interimTranscript; // Append interim transcript to final transcript\n      lastLoggedInterimTranscript = interimTranscript; // Update last logged interim\n      console.log('Appended Interim Transcript to Final:', finalTranscript);\n    }\n\n    // Log interim transcript only when it's new or updated\n    if (interimTranscript && interimTranscript !== lastLoggedInterimTranscript) {\n      console.log('Updated Interim Transcript:', interimTranscript);\n    }\n  };\n\n  // Handle when recognition ends and restart if necessary (without sending transcript)\n  recognition.onend = () => {\n    console.log('Speech recognition ended.');\n\n    // Only restart recognition if it wasn't stopped manually\n    if (isRecognitionRunning) {\n      console.log('Restarting speech recognition...');\n      recognition.start(); // Automatically restart recognition\n    }\n  };\n\n  // Handle errors during recognition\n  recognition.onerror = event => {\n    console.error('Speech Recognition Error:', event.error);\n    if (event.error === 'no-speech') {\n      alert('No speech detected. Please try again.');\n      setTimeout(() => {\n        startSpeechRecognition();\n      }, 1000); // Restart after 1 second if no speech is detected\n    }\n    if (event.error === 'audio-capture') {\n      alert('Please check your microphone permissions.');\n    }\n\n    // Handle other potential errors\n    if (event.error === 'aborted' || event.error === 'network') {\n      console.error('Speech recognition was aborted or there was a network issue.');\n      recognition.start(); // Restart if it's a recoverable error\n    }\n  };\n}\n\n// Function to request microphone permission\nasync function requestMicPermission() {\n  try {\n    const stream = await navigator.mediaDevices.getUserMedia({\n      audio: true\n    });\n    console.log('Microphone permission granted');\n    stream.getTracks().forEach(track => track.stop()); // Stop the stream immediately after permission is granted\n    return true;\n  } catch (error) {\n    console.error('Microphone permission denied:', error);\n    alert('Microphone access is required for speech recognition.');\n    return false;\n  }\n}\n\n// Start speech recognition function\nexport async function startSpeechRecognition() {\n  const permissionGranted = await requestMicPermission(); // Ensure microphone permission is granted\n  if (!permissionGranted) return;\n  if (isRecognitionRunning) {\n    console.error(\"Speech recognition is already running.\");\n    return;\n  }\n  finalTranscript = ''; // Clear the transcript at the start of a new session\n  initializeRecognition(); // Initialize the recognition instance\n  try {\n    recognition.start(); // Start speech recognition\n    isRecognitionRunning = true; // Mark recognition as running\n    console.log('Speech recognition started.');\n  } catch (error) {\n    console.error('Error starting speech recognition:', error);\n  }\n}\n\n// Stop speech recognition function (and send transcript)\nexport function stopSpeechRecognition() {\n  if (!isRecognitionRunning) {\n    console.error(\"Speech recognition is not running.\");\n    return;\n  }\n  console.log('Stopping speech recognition...');\n  recognition.stop(); // Stop recognition\n  isRecognitionRunning = false; // Mark recognition as stopped\n\n  // Send the final transcript to the backend for processing\n  if (finalTranscript) {\n    console.log('Sending final transcript to backend.');\n    processTranscript(finalTranscript); // Send the complete transcript to the backend\n    finalTranscript = ''; // Clear the final transcript for the next session\n  }\n}\n\n// Process the final transcript and send to backend\nexport const processTranscript = async transcript => {\n  try {\n    // Send as JSON because the backend likely expects a JSON payload\n    const response = await fetch('http://localhost:3001/generateNotes', {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json'\n      },\n      body: JSON.stringify({\n        transcript\n      }) // Send the transcript as JSON\n    });\n    if (!response.ok) {\n      throw new Error(`Server error: ${response.status}`);\n    }\n    const result = await response.json();\n    console.log('Generated notes:', result); // Log the generated notes from the backend\n  } catch (error) {\n    console.error('Error sending transcript to backend:', error); // Log errors that occur during the API call\n  }\n};","map":{"version":3,"names":["isRecognitionRunning","finalTranscript","recognition","INTERIM_THRESHOLD","lastLoggedInterimTranscript","logCount","logWithLimit","message","console","clear","log","checkSpeechRecognitionSupport","window","SpeechRecognition","webkitSpeechRecognition","error","alert","initializeRecognition","continuous","interimResults","lang","onresult","event","interimTranscript","i","resultIndex","results","length","result","isFinal","transcript","onend","start","onerror","setTimeout","startSpeechRecognition","requestMicPermission","stream","navigator","mediaDevices","getUserMedia","audio","getTracks","forEach","track","stop","permissionGranted","stopSpeechRecognition","processTranscript","response","fetch","method","headers","body","JSON","stringify","ok","Error","status","json"],"sources":["/Users/ayushbhanot/Documents/Coding/Riipen/AITranscriptionApp/aitranscriptionapp/src/services/audioRecording.js"],"sourcesContent":["let isRecognitionRunning = false;\nlet finalTranscript = ''; \nlet recognition;\nconst INTERIM_THRESHOLD = 100;  // Set a character length threshold for interim transcript\nlet lastLoggedInterimTranscript = '';  // Store the last logged interim transcript to compare\n\nlet logCount = 0;\n\nfunction logWithLimit(message) {\n    logCount++;\n\n    if (logCount % 50 === 0) {  // Clear console after every 100 logs\n        console.clear();\n    }\n\n    console.log(message);\n}\n\n\n// Function to check WebkitSpeechRecognition support\nfunction checkSpeechRecognitionSupport() {\n    window.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n    if (!window.SpeechRecognition) {\n        console.error('SpeechRecognition API not supported.');\n        alert('Your browser does not support speech recognition features.');\n        return false;\n    }\n    return true;\n}\n\n// Check for WebkitSpeechRecognition support early\nif (!checkSpeechRecognitionSupport()) {\n    alert('Your browser does not support the necessary speech recognition features.');\n}\n\n// Initialize WebkitSpeechRecognition\nfunction initializeRecognition() {\n    recognition = new window.SpeechRecognition();\n    recognition.continuous = true;  // Allow continuous recognition\n    recognition.interimResults = true;  // Capture partial results for real-time updates\n    recognition.lang = 'en-US';  // Set recognition language\n\n    // Handle recognition results (interim and final)\n    recognition.onresult = (event) => {\n        let interimTranscript = '';\n\n        // Iterate through results starting from the event.resultIndex\n        for (let i = event.resultIndex; i < event.results.length; i++) {\n            const result = event.results[i];\n\n            // If the result is final, append it to the final transcript\n            if (result.isFinal) {\n                finalTranscript += result[0].transcript;  // Append to final transcript\n                console.log('Final Transcript So Far:', finalTranscript);  // Log final transcript\n            } else {\n                interimTranscript += result[0].transcript;  // Append interim transcripts\n            }\n        }\n\n        // Check if the interim transcript is new and has changed significantly\n        if (interimTranscript !== lastLoggedInterimTranscript && interimTranscript.length >= INTERIM_THRESHOLD) {\n            finalTranscript += interimTranscript;  // Append interim transcript to final transcript\n            lastLoggedInterimTranscript = interimTranscript;  // Update last logged interim\n            console.log('Appended Interim Transcript to Final:', finalTranscript);\n        }\n\n        // Log interim transcript only when it's new or updated\n        if (interimTranscript && interimTranscript !== lastLoggedInterimTranscript) {\n            console.log('Updated Interim Transcript:', interimTranscript);\n        }\n    };\n\n    // Handle when recognition ends and restart if necessary (without sending transcript)\n    recognition.onend = () => {\n        console.log('Speech recognition ended.');\n\n        // Only restart recognition if it wasn't stopped manually\n        if (isRecognitionRunning) {\n            console.log('Restarting speech recognition...');\n            recognition.start();  // Automatically restart recognition\n        }\n    };\n\n    // Handle errors during recognition\n    recognition.onerror = (event) => {\n        console.error('Speech Recognition Error:', event.error);\n    \n        if (event.error === 'no-speech') {\n            alert('No speech detected. Please try again.');\n            setTimeout(() => {\n                startSpeechRecognition();\n            }, 1000);  // Restart after 1 second if no speech is detected\n        }\n    \n        if (event.error === 'audio-capture') {\n            alert('Please check your microphone permissions.');\n        }\n    \n        // Handle other potential errors\n        if (event.error === 'aborted' || event.error === 'network') {\n            console.error('Speech recognition was aborted or there was a network issue.');\n            recognition.start();  // Restart if it's a recoverable error\n        }\n    };\n    \n    \n}\n\n// Function to request microphone permission\nasync function requestMicPermission() {\n    try {\n        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n        console.log('Microphone permission granted');\n        stream.getTracks().forEach(track => track.stop());  // Stop the stream immediately after permission is granted\n        return true;\n    } catch (error) {\n        console.error('Microphone permission denied:', error);\n        alert('Microphone access is required for speech recognition.');\n        return false;\n    }\n}\n\n// Start speech recognition function\nexport async function startSpeechRecognition() {\n    const permissionGranted = await requestMicPermission();  // Ensure microphone permission is granted\n    if (!permissionGranted) return;\n\n    if (isRecognitionRunning) {\n        console.error(\"Speech recognition is already running.\");\n        return;\n    }\n\n    finalTranscript = '';  // Clear the transcript at the start of a new session\n    initializeRecognition();  // Initialize the recognition instance\n    try {\n        recognition.start();  // Start speech recognition\n        isRecognitionRunning = true;  // Mark recognition as running\n        console.log('Speech recognition started.');\n    } catch (error) {\n        console.error('Error starting speech recognition:', error);\n    }\n}\n\n// Stop speech recognition function (and send transcript)\nexport function stopSpeechRecognition() {\n    if (!isRecognitionRunning) {\n        console.error(\"Speech recognition is not running.\");\n        return;\n    }\n    console.log('Stopping speech recognition...');\n    recognition.stop();  // Stop recognition\n    isRecognitionRunning = false;  // Mark recognition as stopped\n\n    // Send the final transcript to the backend for processing\n    if (finalTranscript) {\n        console.log('Sending final transcript to backend.');\n        processTranscript(finalTranscript);  // Send the complete transcript to the backend\n        finalTranscript = '';  // Clear the final transcript for the next session\n    }\n}\n\n// Process the final transcript and send to backend\nexport const processTranscript = async (transcript) => {\n    try {\n        // Send as JSON because the backend likely expects a JSON payload\n        const response = await fetch('http://localhost:3001/generateNotes', {\n            method: 'POST',\n            headers: {\n                'Content-Type': 'application/json',\n            },\n            body: JSON.stringify({ transcript }),  // Send the transcript as JSON\n        });\n\n        if (!response.ok) {\n            throw new Error(`Server error: ${response.status}`);\n        }\n\n        const result = await response.json();\n        console.log('Generated notes:', result);  // Log the generated notes from the backend\n    } catch (error) {\n        console.error('Error sending transcript to backend:', error);  // Log errors that occur during the API call\n    }\n};\n"],"mappings":"AAAA,IAAIA,oBAAoB,GAAG,KAAK;AAChC,IAAIC,eAAe,GAAG,EAAE;AACxB,IAAIC,WAAW;AACf,MAAMC,iBAAiB,GAAG,GAAG,CAAC,CAAE;AAChC,IAAIC,2BAA2B,GAAG,EAAE,CAAC,CAAE;;AAEvC,IAAIC,QAAQ,GAAG,CAAC;AAEhB,SAASC,YAAYA,CAACC,OAAO,EAAE;EAC3BF,QAAQ,EAAE;EAEV,IAAIA,QAAQ,GAAG,EAAE,KAAK,CAAC,EAAE;IAAG;IACxBG,OAAO,CAACC,KAAK,CAAC,CAAC;EACnB;EAEAD,OAAO,CAACE,GAAG,CAACH,OAAO,CAAC;AACxB;;AAGA;AACA,SAASI,6BAA6BA,CAAA,EAAG;EACrCC,MAAM,CAACC,iBAAiB,GAAGD,MAAM,CAACC,iBAAiB,IAAID,MAAM,CAACE,uBAAuB;EACrF,IAAI,CAACF,MAAM,CAACC,iBAAiB,EAAE;IAC3BL,OAAO,CAACO,KAAK,CAAC,sCAAsC,CAAC;IACrDC,KAAK,CAAC,4DAA4D,CAAC;IACnE,OAAO,KAAK;EAChB;EACA,OAAO,IAAI;AACf;;AAEA;AACA,IAAI,CAACL,6BAA6B,CAAC,CAAC,EAAE;EAClCK,KAAK,CAAC,0EAA0E,CAAC;AACrF;;AAEA;AACA,SAASC,qBAAqBA,CAAA,EAAG;EAC7Bf,WAAW,GAAG,IAAIU,MAAM,CAACC,iBAAiB,CAAC,CAAC;EAC5CX,WAAW,CAACgB,UAAU,GAAG,IAAI,CAAC,CAAE;EAChChB,WAAW,CAACiB,cAAc,GAAG,IAAI,CAAC,CAAE;EACpCjB,WAAW,CAACkB,IAAI,GAAG,OAAO,CAAC,CAAE;;EAE7B;EACAlB,WAAW,CAACmB,QAAQ,GAAIC,KAAK,IAAK;IAC9B,IAAIC,iBAAiB,GAAG,EAAE;;IAE1B;IACA,KAAK,IAAIC,CAAC,GAAGF,KAAK,CAACG,WAAW,EAAED,CAAC,GAAGF,KAAK,CAACI,OAAO,CAACC,MAAM,EAAEH,CAAC,EAAE,EAAE;MAC3D,MAAMI,MAAM,GAAGN,KAAK,CAACI,OAAO,CAACF,CAAC,CAAC;;MAE/B;MACA,IAAII,MAAM,CAACC,OAAO,EAAE;QAChB5B,eAAe,IAAI2B,MAAM,CAAC,CAAC,CAAC,CAACE,UAAU,CAAC,CAAE;QAC1CtB,OAAO,CAACE,GAAG,CAAC,0BAA0B,EAAET,eAAe,CAAC,CAAC,CAAE;MAC/D,CAAC,MAAM;QACHsB,iBAAiB,IAAIK,MAAM,CAAC,CAAC,CAAC,CAACE,UAAU,CAAC,CAAE;MAChD;IACJ;;IAEA;IACA,IAAIP,iBAAiB,KAAKnB,2BAA2B,IAAImB,iBAAiB,CAACI,MAAM,IAAIxB,iBAAiB,EAAE;MACpGF,eAAe,IAAIsB,iBAAiB,CAAC,CAAE;MACvCnB,2BAA2B,GAAGmB,iBAAiB,CAAC,CAAE;MAClDf,OAAO,CAACE,GAAG,CAAC,uCAAuC,EAAET,eAAe,CAAC;IACzE;;IAEA;IACA,IAAIsB,iBAAiB,IAAIA,iBAAiB,KAAKnB,2BAA2B,EAAE;MACxEI,OAAO,CAACE,GAAG,CAAC,6BAA6B,EAAEa,iBAAiB,CAAC;IACjE;EACJ,CAAC;;EAED;EACArB,WAAW,CAAC6B,KAAK,GAAG,MAAM;IACtBvB,OAAO,CAACE,GAAG,CAAC,2BAA2B,CAAC;;IAExC;IACA,IAAIV,oBAAoB,EAAE;MACtBQ,OAAO,CAACE,GAAG,CAAC,kCAAkC,CAAC;MAC/CR,WAAW,CAAC8B,KAAK,CAAC,CAAC,CAAC,CAAE;IAC1B;EACJ,CAAC;;EAED;EACA9B,WAAW,CAAC+B,OAAO,GAAIX,KAAK,IAAK;IAC7Bd,OAAO,CAACO,KAAK,CAAC,2BAA2B,EAAEO,KAAK,CAACP,KAAK,CAAC;IAEvD,IAAIO,KAAK,CAACP,KAAK,KAAK,WAAW,EAAE;MAC7BC,KAAK,CAAC,uCAAuC,CAAC;MAC9CkB,UAAU,CAAC,MAAM;QACbC,sBAAsB,CAAC,CAAC;MAC5B,CAAC,EAAE,IAAI,CAAC,CAAC,CAAE;IACf;IAEA,IAAIb,KAAK,CAACP,KAAK,KAAK,eAAe,EAAE;MACjCC,KAAK,CAAC,2CAA2C,CAAC;IACtD;;IAEA;IACA,IAAIM,KAAK,CAACP,KAAK,KAAK,SAAS,IAAIO,KAAK,CAACP,KAAK,KAAK,SAAS,EAAE;MACxDP,OAAO,CAACO,KAAK,CAAC,8DAA8D,CAAC;MAC7Eb,WAAW,CAAC8B,KAAK,CAAC,CAAC,CAAC,CAAE;IAC1B;EACJ,CAAC;AAGL;;AAEA;AACA,eAAeI,oBAAoBA,CAAA,EAAG;EAClC,IAAI;IACA,MAAMC,MAAM,GAAG,MAAMC,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;MAAEC,KAAK,EAAE;IAAK,CAAC,CAAC;IACzEjC,OAAO,CAACE,GAAG,CAAC,+BAA+B,CAAC;IAC5C2B,MAAM,CAACK,SAAS,CAAC,CAAC,CAACC,OAAO,CAACC,KAAK,IAAIA,KAAK,CAACC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAE;IACpD,OAAO,IAAI;EACf,CAAC,CAAC,OAAO9B,KAAK,EAAE;IACZP,OAAO,CAACO,KAAK,CAAC,+BAA+B,EAAEA,KAAK,CAAC;IACrDC,KAAK,CAAC,uDAAuD,CAAC;IAC9D,OAAO,KAAK;EAChB;AACJ;;AAEA;AACA,OAAO,eAAemB,sBAAsBA,CAAA,EAAG;EAC3C,MAAMW,iBAAiB,GAAG,MAAMV,oBAAoB,CAAC,CAAC,CAAC,CAAE;EACzD,IAAI,CAACU,iBAAiB,EAAE;EAExB,IAAI9C,oBAAoB,EAAE;IACtBQ,OAAO,CAACO,KAAK,CAAC,wCAAwC,CAAC;IACvD;EACJ;EAEAd,eAAe,GAAG,EAAE,CAAC,CAAE;EACvBgB,qBAAqB,CAAC,CAAC,CAAC,CAAE;EAC1B,IAAI;IACAf,WAAW,CAAC8B,KAAK,CAAC,CAAC,CAAC,CAAE;IACtBhC,oBAAoB,GAAG,IAAI,CAAC,CAAE;IAC9BQ,OAAO,CAACE,GAAG,CAAC,6BAA6B,CAAC;EAC9C,CAAC,CAAC,OAAOK,KAAK,EAAE;IACZP,OAAO,CAACO,KAAK,CAAC,oCAAoC,EAAEA,KAAK,CAAC;EAC9D;AACJ;;AAEA;AACA,OAAO,SAASgC,qBAAqBA,CAAA,EAAG;EACpC,IAAI,CAAC/C,oBAAoB,EAAE;IACvBQ,OAAO,CAACO,KAAK,CAAC,oCAAoC,CAAC;IACnD;EACJ;EACAP,OAAO,CAACE,GAAG,CAAC,gCAAgC,CAAC;EAC7CR,WAAW,CAAC2C,IAAI,CAAC,CAAC,CAAC,CAAE;EACrB7C,oBAAoB,GAAG,KAAK,CAAC,CAAE;;EAE/B;EACA,IAAIC,eAAe,EAAE;IACjBO,OAAO,CAACE,GAAG,CAAC,sCAAsC,CAAC;IACnDsC,iBAAiB,CAAC/C,eAAe,CAAC,CAAC,CAAE;IACrCA,eAAe,GAAG,EAAE,CAAC,CAAE;EAC3B;AACJ;;AAEA;AACA,OAAO,MAAM+C,iBAAiB,GAAG,MAAOlB,UAAU,IAAK;EACnD,IAAI;IACA;IACA,MAAMmB,QAAQ,GAAG,MAAMC,KAAK,CAAC,qCAAqC,EAAE;MAChEC,MAAM,EAAE,MAAM;MACdC,OAAO,EAAE;QACL,cAAc,EAAE;MACpB,CAAC;MACDC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;QAAEzB;MAAW,CAAC,CAAC,CAAG;IAC3C,CAAC,CAAC;IAEF,IAAI,CAACmB,QAAQ,CAACO,EAAE,EAAE;MACd,MAAM,IAAIC,KAAK,CAAC,iBAAiBR,QAAQ,CAACS,MAAM,EAAE,CAAC;IACvD;IAEA,MAAM9B,MAAM,GAAG,MAAMqB,QAAQ,CAACU,IAAI,CAAC,CAAC;IACpCnD,OAAO,CAACE,GAAG,CAAC,kBAAkB,EAAEkB,MAAM,CAAC,CAAC,CAAE;EAC9C,CAAC,CAAC,OAAOb,KAAK,EAAE;IACZP,OAAO,CAACO,KAAK,CAAC,sCAAsC,EAAEA,KAAK,CAAC,CAAC,CAAE;EACnE;AACJ,CAAC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}