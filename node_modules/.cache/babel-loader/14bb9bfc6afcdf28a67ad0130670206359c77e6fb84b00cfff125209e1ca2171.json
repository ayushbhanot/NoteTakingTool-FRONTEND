{"ast":null,"code":"// let mediaRecorder = null; // Declare globally (commented out, we won't use MediaRecorder)\n// Function to check WebkitSpeechRecognition support\nfunction checkSpeechRecognitionSupport(){window.SpeechRecognition=window.SpeechRecognition||window.webkitSpeechRecognition;if(!window.SpeechRecognition){console.error('SpeechRecognition API not supported.');alert('Your browser does not support speech recognition features.');return false;}return true;}// Check for WebkitSpeechRecognition support early\nif(!checkSpeechRecognitionSupport()){alert('Your browser does not support the necessary speech recognition features.');}// Initialize WebkitSpeechRecognition\nconst recognition=new window.SpeechRecognition();recognition.continuous=true;recognition.interimResults=false;recognition.lang='en-US';// Start speech recognition function\nexport async function startSpeechRecognition(){console.log('Attempting to start speech recognition...');try{recognition.start();}catch(error){console.error('Error starting speech recognition:',error);}}// Stop speech recognition function\nexport function stopSpeechRecognition(){console.log('Stopping speech recognition...');recognition.stop();}// Process the transcript and send to backend\nexport const processTranscript=async transcript=>{const formData=new FormData();formData.append('transcript',transcript);try{const response=await fetch('http://localhost:3001/generateNotes',{method:'POST',body:formData});if(!response.ok){throw new Error(`Server error: ${response.status}`);}const result=await response.json();console.log('Generated notes:',result);}catch(error){console.error('Error sending transcript to backend:',error);}};// Event handler for when recognition results are available\nrecognition.onresult=event=>{const transcript=Array.from(event.results).map(result=>result[0].transcript).join('');console.log('Transcript:',transcript);processTranscript(transcript);// Process the transcript\n};recognition.onerror=event=>{console.error('Speech Recognition Error:',event.error);};// COMMENTED OUT MEDIARECORDER CODE\n/*\nexport async function startRecording() {\n    console.log('Attempting to start recording...');\n    try {\n        const micStream = await navigator.mediaDevices.getUserMedia({\n            audio: {\n                echoCancellation: false,\n                noiseSuppression: false,\n                sampleRate: 44100\n            }\n        });\n        console.log('Microphone stream acquired:', micStream);\n\n        const combinedStream = micStream;\n        console.log('Combined stream:', combinedStream);\n\n        if (combinedStream.getAudioTracks().length === 0) {\n            throw new Error('Combined stream has no audio tracks.');\n        }\n\n        let options = { mimeType: 'audio/webm; codecs=opus' };\n        if (!MediaRecorder.isTypeSupported(options.mimeType)) {\n            options = { mimeType: 'audio/webm' };\n        }\n       if (!MediaRecorder.isTypeSupported(options.mimeType)) {\n            options = { mimeType: 'audio/mp4' };\n        }\n        if (!MediaRecorder.isTypeSupported(options.mimeType)) {\n            options = {};\n        }\n\n        mediaRecorder = new MediaRecorder(combinedStream, options);\n        console.log('MediaRecorder initialized:', mediaRecorder);\n\n        let audioChunks = [];\n        mediaRecorder.ondataavailable = (event) => {\n            if (event.data.size > 0) {\n                audioChunks.push(event.data);\n                console.log('Audio chunk available:', event.data);\n            }\n        };\n\n        mediaRecorder.onstart = () => {\n            console.log('Recording started.');\n        };\n\n        mediaRecorder.onstop = () => {\n            console.log('Recording stopped.');\n            const audioBlob = new Blob(audioChunks, { type: options.mimeType || 'audio/webm' });\n            console.log('Audio Blob size:', audioBlob.size);\n            if (audioBlob.size > 0) {\n                processAudioChunk(audioBlob);\n            } else {\n                console.error('Audio Blob is empty, not sending to backend');\n            }\n        };\n\n        mediaRecorder.onerror = (event) => {\n            console.error('MediaRecorder error:', event.error);\n        };\n\n        mediaRecorder.start();\n    } catch (error) {\n        console.error('Error capturing audio:', error);\n    }\n}\n\nexport function stopRecording() {\n    if (mediaRecorder) {\n        if (mediaRecorder.state !== 'inactive') {\n            console.log('Stopping recording...');\n            mediaRecorder.stop();\n        } else {\n            console.error('MediaRecorder is inactive.');\n        }\n    } else {\n        console.error('No MediaRecorder instance found.');\n    }\n}\n*/","map":{"version":3,"names":["checkSpeechRecognitionSupport","window","SpeechRecognition","webkitSpeechRecognition","console","error","alert","recognition","continuous","interimResults","lang","startSpeechRecognition","log","start","stopSpeechRecognition","stop","processTranscript","transcript","formData","FormData","append","response","fetch","method","body","ok","Error","status","result","json","onresult","event","Array","from","results","map","join","onerror"],"sources":["/Users/ayushbhanot/Documents/Coding/Riipen/AITranscriptionApp/aitranscriptionapp/src/services/audioRecording.js"],"sourcesContent":["// let mediaRecorder = null; // Declare globally (commented out, we won't use MediaRecorder)\n\n// Function to check WebkitSpeechRecognition support\nfunction checkSpeechRecognitionSupport() {\n    window.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n    if (!window.SpeechRecognition) {\n        console.error('SpeechRecognition API not supported.');\n        alert('Your browser does not support speech recognition features.');\n        return false;\n    }\n    return true;\n}\n\n// Check for WebkitSpeechRecognition support early\nif (!checkSpeechRecognitionSupport()) {\n    alert('Your browser does not support the necessary speech recognition features.');\n}\n\n// Initialize WebkitSpeechRecognition\nconst recognition = new window.SpeechRecognition();\nrecognition.continuous = true;\nrecognition.interimResults = false;\nrecognition.lang = 'en-US';\n\n// Start speech recognition function\nexport async function startSpeechRecognition() {\n    console.log('Attempting to start speech recognition...');\n    try {\n        recognition.start();\n    } catch (error) {\n        console.error('Error starting speech recognition:', error);\n    }\n}\n\n// Stop speech recognition function\nexport function stopSpeechRecognition() {\n    console.log('Stopping speech recognition...');\n    recognition.stop();\n}\n\n// Process the transcript and send to backend\nexport const processTranscript = async (transcript) => {\n    const formData = new FormData();\n    formData.append('transcript', transcript);\n\n    try {\n        const response = await fetch('http://localhost:3001/generateNotes', {\n            method: 'POST',\n            body: formData,\n        });\n\n        if (!response.ok) {\n            throw new Error(`Server error: ${response.status}`);\n        }\n\n        const result = await response.json();\n        console.log('Generated notes:', result);\n    } catch (error) {\n        console.error('Error sending transcript to backend:', error);\n    }\n};\n\n// Event handler for when recognition results are available\nrecognition.onresult = (event) => {\n    const transcript = Array.from(event.results)\n        .map(result => result[0].transcript)\n        .join('');\n    console.log('Transcript:', transcript);\n    processTranscript(transcript); // Process the transcript\n};\n\nrecognition.onerror = (event) => {\n    console.error('Speech Recognition Error:', event.error);\n};\n\n// COMMENTED OUT MEDIARECORDER CODE\n/*\nexport async function startRecording() {\n    console.log('Attempting to start recording...');\n    try {\n        const micStream = await navigator.mediaDevices.getUserMedia({\n            audio: {\n                echoCancellation: false,\n                noiseSuppression: false,\n                sampleRate: 44100\n            }\n        });\n        console.log('Microphone stream acquired:', micStream);\n\n        const combinedStream = micStream;\n        console.log('Combined stream:', combinedStream);\n\n        if (combinedStream.getAudioTracks().length === 0) {\n            throw new Error('Combined stream has no audio tracks.');\n        }\n\n        let options = { mimeType: 'audio/webm; codecs=opus' };\n        if (!MediaRecorder.isTypeSupported(options.mimeType)) {\n            options = { mimeType: 'audio/webm' };\n        }\n       if (!MediaRecorder.isTypeSupported(options.mimeType)) {\n            options = { mimeType: 'audio/mp4' };\n        }\n        if (!MediaRecorder.isTypeSupported(options.mimeType)) {\n            options = {};\n        }\n\n        mediaRecorder = new MediaRecorder(combinedStream, options);\n        console.log('MediaRecorder initialized:', mediaRecorder);\n\n        let audioChunks = [];\n        mediaRecorder.ondataavailable = (event) => {\n            if (event.data.size > 0) {\n                audioChunks.push(event.data);\n                console.log('Audio chunk available:', event.data);\n            }\n        };\n\n        mediaRecorder.onstart = () => {\n            console.log('Recording started.');\n        };\n\n        mediaRecorder.onstop = () => {\n            console.log('Recording stopped.');\n            const audioBlob = new Blob(audioChunks, { type: options.mimeType || 'audio/webm' });\n            console.log('Audio Blob size:', audioBlob.size);\n            if (audioBlob.size > 0) {\n                processAudioChunk(audioBlob);\n            } else {\n                console.error('Audio Blob is empty, not sending to backend');\n            }\n        };\n\n        mediaRecorder.onerror = (event) => {\n            console.error('MediaRecorder error:', event.error);\n        };\n\n        mediaRecorder.start();\n    } catch (error) {\n        console.error('Error capturing audio:', error);\n    }\n}\n\nexport function stopRecording() {\n    if (mediaRecorder) {\n        if (mediaRecorder.state !== 'inactive') {\n            console.log('Stopping recording...');\n            mediaRecorder.stop();\n        } else {\n            console.error('MediaRecorder is inactive.');\n        }\n    } else {\n        console.error('No MediaRecorder instance found.');\n    }\n}\n*/\n"],"mappings":"AAAA;AAEA;AACA,QAAS,CAAAA,6BAA6BA,CAAA,CAAG,CACrCC,MAAM,CAACC,iBAAiB,CAAGD,MAAM,CAACC,iBAAiB,EAAID,MAAM,CAACE,uBAAuB,CACrF,GAAI,CAACF,MAAM,CAACC,iBAAiB,CAAE,CAC3BE,OAAO,CAACC,KAAK,CAAC,sCAAsC,CAAC,CACrDC,KAAK,CAAC,4DAA4D,CAAC,CACnE,MAAO,MAAK,CAChB,CACA,MAAO,KAAI,CACf,CAEA;AACA,GAAI,CAACN,6BAA6B,CAAC,CAAC,CAAE,CAClCM,KAAK,CAAC,0EAA0E,CAAC,CACrF,CAEA;AACA,KAAM,CAAAC,WAAW,CAAG,GAAI,CAAAN,MAAM,CAACC,iBAAiB,CAAC,CAAC,CAClDK,WAAW,CAACC,UAAU,CAAG,IAAI,CAC7BD,WAAW,CAACE,cAAc,CAAG,KAAK,CAClCF,WAAW,CAACG,IAAI,CAAG,OAAO,CAE1B;AACA,MAAO,eAAe,CAAAC,sBAAsBA,CAAA,CAAG,CAC3CP,OAAO,CAACQ,GAAG,CAAC,2CAA2C,CAAC,CACxD,GAAI,CACAL,WAAW,CAACM,KAAK,CAAC,CAAC,CACvB,CAAE,MAAOR,KAAK,CAAE,CACZD,OAAO,CAACC,KAAK,CAAC,oCAAoC,CAAEA,KAAK,CAAC,CAC9D,CACJ,CAEA;AACA,MAAO,SAAS,CAAAS,qBAAqBA,CAAA,CAAG,CACpCV,OAAO,CAACQ,GAAG,CAAC,gCAAgC,CAAC,CAC7CL,WAAW,CAACQ,IAAI,CAAC,CAAC,CACtB,CAEA;AACA,MAAO,MAAM,CAAAC,iBAAiB,CAAG,KAAO,CAAAC,UAAU,EAAK,CACnD,KAAM,CAAAC,QAAQ,CAAG,GAAI,CAAAC,QAAQ,CAAC,CAAC,CAC/BD,QAAQ,CAACE,MAAM,CAAC,YAAY,CAAEH,UAAU,CAAC,CAEzC,GAAI,CACA,KAAM,CAAAI,QAAQ,CAAG,KAAM,CAAAC,KAAK,CAAC,qCAAqC,CAAE,CAChEC,MAAM,CAAE,MAAM,CACdC,IAAI,CAAEN,QACV,CAAC,CAAC,CAEF,GAAI,CAACG,QAAQ,CAACI,EAAE,CAAE,CACd,KAAM,IAAI,CAAAC,KAAK,CAAC,iBAAiBL,QAAQ,CAACM,MAAM,EAAE,CAAC,CACvD,CAEA,KAAM,CAAAC,MAAM,CAAG,KAAM,CAAAP,QAAQ,CAACQ,IAAI,CAAC,CAAC,CACpCzB,OAAO,CAACQ,GAAG,CAAC,kBAAkB,CAAEgB,MAAM,CAAC,CAC3C,CAAE,MAAOvB,KAAK,CAAE,CACZD,OAAO,CAACC,KAAK,CAAC,sCAAsC,CAAEA,KAAK,CAAC,CAChE,CACJ,CAAC,CAED;AACAE,WAAW,CAACuB,QAAQ,CAAIC,KAAK,EAAK,CAC9B,KAAM,CAAAd,UAAU,CAAGe,KAAK,CAACC,IAAI,CAACF,KAAK,CAACG,OAAO,CAAC,CACvCC,GAAG,CAACP,MAAM,EAAIA,MAAM,CAAC,CAAC,CAAC,CAACX,UAAU,CAAC,CACnCmB,IAAI,CAAC,EAAE,CAAC,CACbhC,OAAO,CAACQ,GAAG,CAAC,aAAa,CAAEK,UAAU,CAAC,CACtCD,iBAAiB,CAACC,UAAU,CAAC,CAAE;AACnC,CAAC,CAEDV,WAAW,CAAC8B,OAAO,CAAIN,KAAK,EAAK,CAC7B3B,OAAO,CAACC,KAAK,CAAC,2BAA2B,CAAE0B,KAAK,CAAC1B,KAAK,CAAC,CAC3D,CAAC,CAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}