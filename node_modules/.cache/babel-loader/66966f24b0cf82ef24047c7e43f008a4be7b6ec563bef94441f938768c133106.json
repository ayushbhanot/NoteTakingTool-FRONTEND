{"ast":null,"code":"// let mediaRecorder = null; // Declare globally (commented out, we won't use MediaRecorder)\n\n// Function to check WebkitSpeechRecognition support\nfunction checkSpeechRecognitionSupport() {\n  window.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n  if (!window.SpeechRecognition) {\n    console.error('SpeechRecognition API not supported.');\n    alert('Your browser does not support speech recognition features.');\n    return false;\n  }\n  return true;\n}\n\n// Check for WebkitSpeechRecognition support early\nif (!checkSpeechRecognitionSupport()) {\n  alert('Your browser does not support the necessary speech recognition features.');\n}\n\n// Initialize WebkitSpeechRecognition\nconst recognition = new window.SpeechRecognition();\nrecognition.continuous = true;\nrecognition.interimResults = true; // Set to true to capture partial results\nrecognition.lang = 'en-US';\nlet isRecognitionRunning = false;\nlet finalTranscript = ''; // Store final transcript globally\n\n// Function to request microphone permission\nasync function requestMicPermission() {\n  try {\n    const stream = await navigator.mediaDevices.getUserMedia({\n      audio: true\n    });\n    console.log('Microphone permission granted');\n    stream.getTracks().forEach(track => track.stop()); // Stop the stream immediately\n    return true;\n  } catch (error) {\n    console.error('Microphone permission denied:', error);\n    alert('Microphone access is required for speech recognition.');\n    return false;\n  }\n}\n\n// Start speech recognition function\nexport async function startSpeechRecognition() {\n  const permissionGranted = await requestMicPermission(); // Ensure permission is granted\n  if (!permissionGranted) return;\n  if (isRecognitionRunning) {\n    console.error(\"Speech recognition is already running.\");\n    return;\n  }\n  try {\n    finalTranscript = ''; // Clear transcript on new session\n    recognition.start();\n    isRecognitionRunning = true;\n    console.log('Speech recognition started.');\n  } catch (error) {\n    console.error('Error starting speech recognition:', error);\n  }\n}\n\n// Stop speech recognition function\nexport function stopSpeechRecognition() {\n  if (!isRecognitionRunning) {\n    console.error(\"Speech recognition is not running.\");\n    return;\n  }\n  console.log('Stopping speech recognition...');\n  recognition.stop();\n}\n\n// Handle when recognition ends\nrecognition.onend = () => {\n  isRecognitionRunning = false;\n  console.log('Speech recognition stopped.');\n\n  // Send the final transcript to backend for transcription when stopped\n  if (finalTranscript) {\n    processTranscript(finalTranscript); // Send final transcript to backend\n  } else {\n    console.error(\"No transcript available to send.\");\n  }\n};\n\n// Handle when recognition is aborted\nrecognition.onabort = event => {\n  console.error('Speech recognition was aborted:', event);\n  // Optionally, restart recognition if needed\n  setTimeout(() => {\n    console.log('Attempting to restart speech recognition...');\n    startSpeechRecognition();\n  }, 1000); // Delay to prevent immediate restart\n};\n\n// Process the transcript and send to backend\nexport const processTranscript = async transcript => {\n  const formData = new FormData();\n  formData.append('transcript', transcript);\n  try {\n    const response = await fetch('http://localhost:3001/generateNotes', {\n      method: 'POST',\n      body: formData\n    });\n    if (!response.ok) {\n      throw new Error(`Server error: ${response.status}`);\n    }\n    const result = await response.json();\n    console.log('Generated notes:', result);\n  } catch (error) {\n    console.error('Error sending transcript to backend:', error);\n  }\n};\n\n// Event handler for when recognition results are available\nrecognition.onresult = event => {\n  const interimTranscript = Array.from(event.results).map(result => result[0].transcript).join('');\n  finalTranscript += interimTranscript; // Append to the final transcript\n  console.log('Interim Transcript:', interimTranscript);\n  console.log('Final Transcript:', finalTranscript); // Keep track of what was captured\n};\nrecognition.onerror = event => {\n  console.error('Speech Recognition Error:', event.error);\n};\n\n// COMMENTED OUT MEDIARECORDER CODE\n/*\nexport async function startRecording() {\n    console.log('Attempting to start recording...');\n    try {\n        const micStream = await navigator.mediaDevices.getUserMedia({\n            audio: {\n                echoCancellation: false,\n                noiseSuppression: false,\n                sampleRate: 44100\n            }\n        });\n        console.log('Microphone stream acquired:', micStream);\n\n        const combinedStream = micStream;\n        console.log('Combined stream:', combinedStream);\n\n        if (combinedStream.getAudioTracks().length === 0) {\n            throw new Error('Combined stream has no audio tracks.');\n        }\n\n        let options = { mimeType: 'audio/webm; codecs=opus' };\n        if (!MediaRecorder.isTypeSupported(options.mimeType)) {\n            options = { mimeType: 'audio/webm' };\n        }\n       if (!MediaRecorder.isTypeSupported(options.mimeType)) {\n            options = { mimeType: 'audio/mp4' };\n        }\n        if (!MediaRecorder.isTypeSupported(options.mimeType)) {\n            options = {};\n        }\n\n        mediaRecorder = new MediaRecorder(combinedStream, options);\n        console.log('MediaRecorder initialized:', mediaRecorder);\n\n        let audioChunks = [];\n        mediaRecorder.ondataavailable = (event) => {\n            if (event.data.size > 0) {\n                audioChunks.push(event.data);\n                console.log('Audio chunk available:', event.data);\n            }\n        };\n\n        mediaRecorder.onstart = () => {\n            console.log('Recording started.');\n        };\n\n        mediaRecorder.onstop = () => {\n            console.log('Recording stopped.');\n            const audioBlob = new Blob(audioChunks, { type: options.mimeType || 'audio/webm' });\n            console.log('Audio Blob size:', audioBlob.size);\n            if (audioBlob.size > 0) {\n                processAudioChunk(audioBlob);\n            } else {\n                console.error('Audio Blob is empty, not sending to backend');\n            }\n        };\n\n        mediaRecorder.onerror = (event) => {\n            console.error('MediaRecorder error:', event.error);\n        };\n\n        mediaRecorder.start();\n    } catch (error) {\n        console.error('Error capturing audio:', error);\n    }\n}\n\nexport function stopRecording() {\n    if (mediaRecorder) {\n        if (mediaRecorder.state !== 'inactive') {\n            console.log('Stopping recording...');\n            mediaRecorder.stop();\n        } else {\n            console.error('MediaRecorder is inactive.');\n        }\n    } else {\n        console.error('No MediaRecorder instance found.');\n    }\n}\n*/","map":{"version":3,"names":["checkSpeechRecognitionSupport","window","SpeechRecognition","webkitSpeechRecognition","console","error","alert","recognition","continuous","interimResults","lang","isRecognitionRunning","finalTranscript","requestMicPermission","stream","navigator","mediaDevices","getUserMedia","audio","log","getTracks","forEach","track","stop","startSpeechRecognition","permissionGranted","start","stopSpeechRecognition","onend","processTranscript","onabort","event","setTimeout","transcript","formData","FormData","append","response","fetch","method","body","ok","Error","status","result","json","onresult","interimTranscript","Array","from","results","map","join","onerror"],"sources":["/Users/ayushbhanot/Documents/Coding/Riipen/AITranscriptionApp/aitranscriptionapp/src/services/audioRecording.js"],"sourcesContent":["// let mediaRecorder = null; // Declare globally (commented out, we won't use MediaRecorder)\n\n// Function to check WebkitSpeechRecognition support\nfunction checkSpeechRecognitionSupport() {\n    window.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n    if (!window.SpeechRecognition) {\n        console.error('SpeechRecognition API not supported.');\n        alert('Your browser does not support speech recognition features.');\n        return false;\n    }\n    return true;\n}\n\n// Check for WebkitSpeechRecognition support early\nif (!checkSpeechRecognitionSupport()) {\n    alert('Your browser does not support the necessary speech recognition features.');\n}\n\n// Initialize WebkitSpeechRecognition\nconst recognition = new window.SpeechRecognition();\nrecognition.continuous = true;\nrecognition.interimResults = true; // Set to true to capture partial results\nrecognition.lang = 'en-US';\nlet isRecognitionRunning = false;\nlet finalTranscript = '';  // Store final transcript globally\n\n// Function to request microphone permission\nasync function requestMicPermission() {\n    try {\n        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n        console.log('Microphone permission granted');\n        stream.getTracks().forEach(track => track.stop());  // Stop the stream immediately\n        return true;\n    } catch (error) {\n        console.error('Microphone permission denied:', error);\n        alert('Microphone access is required for speech recognition.');\n        return false;\n    }\n}\n\n// Start speech recognition function\nexport async function startSpeechRecognition() {\n    const permissionGranted = await requestMicPermission();  // Ensure permission is granted\n    if (!permissionGranted) return;\n\n    if (isRecognitionRunning) {\n        console.error(\"Speech recognition is already running.\");\n        return;\n    }\n    try {\n        finalTranscript = '';  // Clear transcript on new session\n        recognition.start();\n        isRecognitionRunning = true;\n        console.log('Speech recognition started.');\n    } catch (error) {\n        console.error('Error starting speech recognition:', error);\n    }\n}\n\n// Stop speech recognition function\nexport function stopSpeechRecognition() {\n    if (!isRecognitionRunning) {\n        console.error(\"Speech recognition is not running.\");\n        return;\n    }\n    console.log('Stopping speech recognition...');\n    recognition.stop();\n}\n\n// Handle when recognition ends\nrecognition.onend = () => {\n    isRecognitionRunning = false;\n    console.log('Speech recognition stopped.');\n    \n    // Send the final transcript to backend for transcription when stopped\n    if (finalTranscript) {\n        processTranscript(finalTranscript);  // Send final transcript to backend\n    } else {\n        console.error(\"No transcript available to send.\");\n    }\n};\n\n// Handle when recognition is aborted\nrecognition.onabort = (event) => {\n    console.error('Speech recognition was aborted:', event);\n    // Optionally, restart recognition if needed\n    setTimeout(() => {\n        console.log('Attempting to restart speech recognition...');\n        startSpeechRecognition();\n    }, 1000);  // Delay to prevent immediate restart\n};\n\n// Process the transcript and send to backend\nexport const processTranscript = async (transcript) => {\n    const formData = new FormData();\n    formData.append('transcript', transcript);\n\n    try {\n        const response = await fetch('http://localhost:3001/generateNotes', {\n            method: 'POST',\n            body: formData,\n        });\n\n        if (!response.ok) {\n            throw new Error(`Server error: ${response.status}`);\n        }\n\n        const result = await response.json();\n        console.log('Generated notes:', result);\n    } catch (error) {\n        console.error('Error sending transcript to backend:', error);\n    }\n};\n\n// Event handler for when recognition results are available\nrecognition.onresult = (event) => {\n    const interimTranscript = Array.from(event.results)\n        .map(result => result[0].transcript)\n        .join('');\n    \n    finalTranscript += interimTranscript;  // Append to the final transcript\n    console.log('Interim Transcript:', interimTranscript);\n    console.log('Final Transcript:', finalTranscript);  // Keep track of what was captured\n};\n\nrecognition.onerror = (event) => {\n    console.error('Speech Recognition Error:', event.error);\n};\n\n// COMMENTED OUT MEDIARECORDER CODE\n/*\nexport async function startRecording() {\n    console.log('Attempting to start recording...');\n    try {\n        const micStream = await navigator.mediaDevices.getUserMedia({\n            audio: {\n                echoCancellation: false,\n                noiseSuppression: false,\n                sampleRate: 44100\n            }\n        });\n        console.log('Microphone stream acquired:', micStream);\n\n        const combinedStream = micStream;\n        console.log('Combined stream:', combinedStream);\n\n        if (combinedStream.getAudioTracks().length === 0) {\n            throw new Error('Combined stream has no audio tracks.');\n        }\n\n        let options = { mimeType: 'audio/webm; codecs=opus' };\n        if (!MediaRecorder.isTypeSupported(options.mimeType)) {\n            options = { mimeType: 'audio/webm' };\n        }\n       if (!MediaRecorder.isTypeSupported(options.mimeType)) {\n            options = { mimeType: 'audio/mp4' };\n        }\n        if (!MediaRecorder.isTypeSupported(options.mimeType)) {\n            options = {};\n        }\n\n        mediaRecorder = new MediaRecorder(combinedStream, options);\n        console.log('MediaRecorder initialized:', mediaRecorder);\n\n        let audioChunks = [];\n        mediaRecorder.ondataavailable = (event) => {\n            if (event.data.size > 0) {\n                audioChunks.push(event.data);\n                console.log('Audio chunk available:', event.data);\n            }\n        };\n\n        mediaRecorder.onstart = () => {\n            console.log('Recording started.');\n        };\n\n        mediaRecorder.onstop = () => {\n            console.log('Recording stopped.');\n            const audioBlob = new Blob(audioChunks, { type: options.mimeType || 'audio/webm' });\n            console.log('Audio Blob size:', audioBlob.size);\n            if (audioBlob.size > 0) {\n                processAudioChunk(audioBlob);\n            } else {\n                console.error('Audio Blob is empty, not sending to backend');\n            }\n        };\n\n        mediaRecorder.onerror = (event) => {\n            console.error('MediaRecorder error:', event.error);\n        };\n\n        mediaRecorder.start();\n    } catch (error) {\n        console.error('Error capturing audio:', error);\n    }\n}\n\nexport function stopRecording() {\n    if (mediaRecorder) {\n        if (mediaRecorder.state !== 'inactive') {\n            console.log('Stopping recording...');\n            mediaRecorder.stop();\n        } else {\n            console.error('MediaRecorder is inactive.');\n        }\n    } else {\n        console.error('No MediaRecorder instance found.');\n    }\n}\n*/\n"],"mappings":"AAAA;;AAEA;AACA,SAASA,6BAA6BA,CAAA,EAAG;EACrCC,MAAM,CAACC,iBAAiB,GAAGD,MAAM,CAACC,iBAAiB,IAAID,MAAM,CAACE,uBAAuB;EACrF,IAAI,CAACF,MAAM,CAACC,iBAAiB,EAAE;IAC3BE,OAAO,CAACC,KAAK,CAAC,sCAAsC,CAAC;IACrDC,KAAK,CAAC,4DAA4D,CAAC;IACnE,OAAO,KAAK;EAChB;EACA,OAAO,IAAI;AACf;;AAEA;AACA,IAAI,CAACN,6BAA6B,CAAC,CAAC,EAAE;EAClCM,KAAK,CAAC,0EAA0E,CAAC;AACrF;;AAEA;AACA,MAAMC,WAAW,GAAG,IAAIN,MAAM,CAACC,iBAAiB,CAAC,CAAC;AAClDK,WAAW,CAACC,UAAU,GAAG,IAAI;AAC7BD,WAAW,CAACE,cAAc,GAAG,IAAI,CAAC,CAAC;AACnCF,WAAW,CAACG,IAAI,GAAG,OAAO;AAC1B,IAAIC,oBAAoB,GAAG,KAAK;AAChC,IAAIC,eAAe,GAAG,EAAE,CAAC,CAAE;;AAE3B;AACA,eAAeC,oBAAoBA,CAAA,EAAG;EAClC,IAAI;IACA,MAAMC,MAAM,GAAG,MAAMC,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;MAAEC,KAAK,EAAE;IAAK,CAAC,CAAC;IACzEd,OAAO,CAACe,GAAG,CAAC,+BAA+B,CAAC;IAC5CL,MAAM,CAACM,SAAS,CAAC,CAAC,CAACC,OAAO,CAACC,KAAK,IAAIA,KAAK,CAACC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAE;IACpD,OAAO,IAAI;EACf,CAAC,CAAC,OAAOlB,KAAK,EAAE;IACZD,OAAO,CAACC,KAAK,CAAC,+BAA+B,EAAEA,KAAK,CAAC;IACrDC,KAAK,CAAC,uDAAuD,CAAC;IAC9D,OAAO,KAAK;EAChB;AACJ;;AAEA;AACA,OAAO,eAAekB,sBAAsBA,CAAA,EAAG;EAC3C,MAAMC,iBAAiB,GAAG,MAAMZ,oBAAoB,CAAC,CAAC,CAAC,CAAE;EACzD,IAAI,CAACY,iBAAiB,EAAE;EAExB,IAAId,oBAAoB,EAAE;IACtBP,OAAO,CAACC,KAAK,CAAC,wCAAwC,CAAC;IACvD;EACJ;EACA,IAAI;IACAO,eAAe,GAAG,EAAE,CAAC,CAAE;IACvBL,WAAW,CAACmB,KAAK,CAAC,CAAC;IACnBf,oBAAoB,GAAG,IAAI;IAC3BP,OAAO,CAACe,GAAG,CAAC,6BAA6B,CAAC;EAC9C,CAAC,CAAC,OAAOd,KAAK,EAAE;IACZD,OAAO,CAACC,KAAK,CAAC,oCAAoC,EAAEA,KAAK,CAAC;EAC9D;AACJ;;AAEA;AACA,OAAO,SAASsB,qBAAqBA,CAAA,EAAG;EACpC,IAAI,CAAChB,oBAAoB,EAAE;IACvBP,OAAO,CAACC,KAAK,CAAC,oCAAoC,CAAC;IACnD;EACJ;EACAD,OAAO,CAACe,GAAG,CAAC,gCAAgC,CAAC;EAC7CZ,WAAW,CAACgB,IAAI,CAAC,CAAC;AACtB;;AAEA;AACAhB,WAAW,CAACqB,KAAK,GAAG,MAAM;EACtBjB,oBAAoB,GAAG,KAAK;EAC5BP,OAAO,CAACe,GAAG,CAAC,6BAA6B,CAAC;;EAE1C;EACA,IAAIP,eAAe,EAAE;IACjBiB,iBAAiB,CAACjB,eAAe,CAAC,CAAC,CAAE;EACzC,CAAC,MAAM;IACHR,OAAO,CAACC,KAAK,CAAC,kCAAkC,CAAC;EACrD;AACJ,CAAC;;AAED;AACAE,WAAW,CAACuB,OAAO,GAAIC,KAAK,IAAK;EAC7B3B,OAAO,CAACC,KAAK,CAAC,iCAAiC,EAAE0B,KAAK,CAAC;EACvD;EACAC,UAAU,CAAC,MAAM;IACb5B,OAAO,CAACe,GAAG,CAAC,6CAA6C,CAAC;IAC1DK,sBAAsB,CAAC,CAAC;EAC5B,CAAC,EAAE,IAAI,CAAC,CAAC,CAAE;AACf,CAAC;;AAED;AACA,OAAO,MAAMK,iBAAiB,GAAG,MAAOI,UAAU,IAAK;EACnD,MAAMC,QAAQ,GAAG,IAAIC,QAAQ,CAAC,CAAC;EAC/BD,QAAQ,CAACE,MAAM,CAAC,YAAY,EAAEH,UAAU,CAAC;EAEzC,IAAI;IACA,MAAMI,QAAQ,GAAG,MAAMC,KAAK,CAAC,qCAAqC,EAAE;MAChEC,MAAM,EAAE,MAAM;MACdC,IAAI,EAAEN;IACV,CAAC,CAAC;IAEF,IAAI,CAACG,QAAQ,CAACI,EAAE,EAAE;MACd,MAAM,IAAIC,KAAK,CAAC,iBAAiBL,QAAQ,CAACM,MAAM,EAAE,CAAC;IACvD;IAEA,MAAMC,MAAM,GAAG,MAAMP,QAAQ,CAACQ,IAAI,CAAC,CAAC;IACpCzC,OAAO,CAACe,GAAG,CAAC,kBAAkB,EAAEyB,MAAM,CAAC;EAC3C,CAAC,CAAC,OAAOvC,KAAK,EAAE;IACZD,OAAO,CAACC,KAAK,CAAC,sCAAsC,EAAEA,KAAK,CAAC;EAChE;AACJ,CAAC;;AAED;AACAE,WAAW,CAACuC,QAAQ,GAAIf,KAAK,IAAK;EAC9B,MAAMgB,iBAAiB,GAAGC,KAAK,CAACC,IAAI,CAAClB,KAAK,CAACmB,OAAO,CAAC,CAC9CC,GAAG,CAACP,MAAM,IAAIA,MAAM,CAAC,CAAC,CAAC,CAACX,UAAU,CAAC,CACnCmB,IAAI,CAAC,EAAE,CAAC;EAEbxC,eAAe,IAAImC,iBAAiB,CAAC,CAAE;EACvC3C,OAAO,CAACe,GAAG,CAAC,qBAAqB,EAAE4B,iBAAiB,CAAC;EACrD3C,OAAO,CAACe,GAAG,CAAC,mBAAmB,EAAEP,eAAe,CAAC,CAAC,CAAE;AACxD,CAAC;AAEDL,WAAW,CAAC8C,OAAO,GAAItB,KAAK,IAAK;EAC7B3B,OAAO,CAACC,KAAK,CAAC,2BAA2B,EAAE0B,KAAK,CAAC1B,KAAK,CAAC;AAC3D,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}