{"ast":null,"code":"let isRecognitionRunning = false;\nlet finalTranscript = ''; // Store final transcript globally\n\n// Function to check WebkitSpeechRecognition support\nfunction checkSpeechRecognitionSupport() {\n  window.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n  if (!window.SpeechRecognition) {\n    console.error('SpeechRecognition API not supported.');\n    alert('Your browser does not support speech recognition features.');\n    return false;\n  }\n  return true;\n}\n\n// Check for WebkitSpeechRecognition support early\nif (!checkSpeechRecognitionSupport()) {\n  alert('Your browser does not support the necessary speech recognition features.');\n}\n\n// Initialize WebkitSpeechRecognition\nfunction initializeRecognition() {\n  recognition = new window.SpeechRecognition();\n  recognition.continuous = true;\n  recognition.interimResults = true; // Set to true to capture partial results\n  recognition.lang = 'en-US';\n  recognition.onresult = event => {\n    let interimTranscript = '';\n\n    // Iterate through the results starting from the event.resultIndex\n    for (let i = event.resultIndex; i < event.results.length; i++) {\n      const result = event.results[i];\n\n      // If the result is final, append it to the final transcript\n      if (result.isFinal) {\n        finalTranscript += result[0].transcript; // Append to the final transcript\n      } else {\n        interimTranscript += result[0].transcript; // Append interim transcripts\n      }\n    }\n\n    // Log interim transcript (optional: remove this if you don't want to see live updates)\n    console.log('Interim Transcript:', interimTranscript);\n\n    // Log the final transcript so far\n    console.log('Final Transcript So Far:', finalTranscript);\n  };\n\n  // Handle when recognition ends, and restart if necessary\n  recognition.onend = () => {\n    console.log('Speech recognition stopped.');\n\n    // If there's a final transcript, send it to the backend for processing\n    if (finalTranscript) {\n      console.log('Sending final transcript to backend.');\n      processTranscript(finalTranscript); // Send the complete transcript to the backend\n      finalTranscript = ''; // Clear the final transcript for the next session\n    }\n\n    // If the user didn't stop it manually, restart recognition if needed\n    if (isRecognitionRunning) {\n      console.log('Restarting speech recognition...');\n      recognition.start(); // Restart recognition automatically\n    }\n  };\n\n  // Handle errors in recognition\n  recognition.onerror = event => {\n    console.error('Speech Recognition Error:', event.error);\n    if (event.error === 'no-speech') {\n      alert('No speech detected. Please try again.');\n      setTimeout(() => {\n        startSpeechRecognition();\n      }, 1000); // Restart after 1 second\n    }\n    if (event.error === 'audio-capture') {\n      alert('Please check your microphone permissions.');\n    }\n  };\n}\n\n// Function to request microphone permission\nasync function requestMicPermission() {\n  try {\n    const stream = await navigator.mediaDevices.getUserMedia({\n      audio: true\n    });\n    console.log('Microphone permission granted');\n    stream.getTracks().forEach(track => track.stop()); // Stop the stream immediately\n    return true;\n  } catch (error) {\n    console.error('Microphone permission denied:', error);\n    alert('Microphone access is required for speech recognition.');\n    return false;\n  }\n}\n\n// Start speech recognition function\nexport async function startSpeechRecognition() {\n  const permissionGranted = await requestMicPermission(); // Ensure permission is granted\n  if (!permissionGranted) return;\n  if (isRecognitionRunning) {\n    console.error(\"Speech recognition is already running.\");\n    return;\n  }\n  finalTranscript = ''; // Clear transcript on new session\n  initializeRecognition(); // Initialize the recognition instance\n  try {\n    recognition.start();\n    isRecognitionRunning = true;\n    console.log('Speech recognition started.');\n  } catch (error) {\n    console.error('Error starting speech recognition:', error);\n  }\n}\n\n// Stop speech recognition function\nexport function stopSpeechRecognition() {\n  if (!isRecognitionRunning) {\n    console.error(\"Speech recognition is not running.\");\n    return;\n  }\n  console.log('Stopping speech recognition...');\n  recognition.stop(); // Stop recognition\n  isRecognitionRunning = false; // Mark recognition as stopped\n}\n\n// Process the final transcript and send to backend\nexport const processTranscript = async transcript => {\n  try {\n    // Send as JSON, because the backend likely expects a JSON payload\n    const response = await fetch('http://localhost:3001/generateNotes', {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json'\n      },\n      body: JSON.stringify({\n        transcript\n      }) // Send the transcript as JSON\n    });\n    if (!response.ok) {\n      throw new Error(`Server error: ${response.status}`);\n    }\n    const result = await response.json();\n    console.log('Generated notes:', result);\n  } catch (error) {\n    console.error('Error sending transcript to backend:', error);\n  }\n};","map":{"version":3,"names":["isRecognitionRunning","finalTranscript","checkSpeechRecognitionSupport","window","SpeechRecognition","webkitSpeechRecognition","console","error","alert","initializeRecognition","recognition","continuous","interimResults","lang","onresult","event","interimTranscript","i","resultIndex","results","length","result","isFinal","transcript","log","onend","processTranscript","start","onerror","setTimeout","startSpeechRecognition","requestMicPermission","stream","navigator","mediaDevices","getUserMedia","audio","getTracks","forEach","track","stop","permissionGranted","stopSpeechRecognition","response","fetch","method","headers","body","JSON","stringify","ok","Error","status","json"],"sources":["/Users/ayushbhanot/Documents/Coding/Riipen/AITranscriptionApp/aitranscriptionapp/src/services/audioRecording.js"],"sourcesContent":["let isRecognitionRunning = false;\nlet finalTranscript = '';  // Store final transcript globally\n\n// Function to check WebkitSpeechRecognition support\nfunction checkSpeechRecognitionSupport() {\n    window.SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n    if (!window.SpeechRecognition) {\n        console.error('SpeechRecognition API not supported.');\n        alert('Your browser does not support speech recognition features.');\n        return false;\n    }\n    return true;\n}\n\n// Check for WebkitSpeechRecognition support early\nif (!checkSpeechRecognitionSupport()) {\n    alert('Your browser does not support the necessary speech recognition features.');\n}\n\n// Initialize WebkitSpeechRecognition\nfunction initializeRecognition() {\n    recognition = new window.SpeechRecognition();\n    recognition.continuous = true;\n    recognition.interimResults = true; // Set to true to capture partial results\n    recognition.lang = 'en-US';\n\n    recognition.onresult = (event) => {\n        let interimTranscript = '';\n\n        // Iterate through the results starting from the event.resultIndex\n        for (let i = event.resultIndex; i < event.results.length; i++) {\n            const result = event.results[i];\n\n            // If the result is final, append it to the final transcript\n            if (result.isFinal) {\n                finalTranscript += result[0].transcript;  // Append to the final transcript\n            } else {\n                interimTranscript += result[0].transcript;  // Append interim transcripts\n            }\n        }\n\n        // Log interim transcript (optional: remove this if you don't want to see live updates)\n        console.log('Interim Transcript:', interimTranscript);\n\n        // Log the final transcript so far\n        console.log('Final Transcript So Far:', finalTranscript);\n    };\n\n    // Handle when recognition ends, and restart if necessary\n    recognition.onend = () => {\n        console.log('Speech recognition stopped.');\n\n        // If there's a final transcript, send it to the backend for processing\n        if (finalTranscript) {\n            console.log('Sending final transcript to backend.');\n            processTranscript(finalTranscript);  // Send the complete transcript to the backend\n            finalTranscript = '';  // Clear the final transcript for the next session\n        }\n\n        // If the user didn't stop it manually, restart recognition if needed\n        if (isRecognitionRunning) {\n            console.log('Restarting speech recognition...');\n            recognition.start();  // Restart recognition automatically\n        }\n    };\n\n    // Handle errors in recognition\n    recognition.onerror = (event) => {\n        console.error('Speech Recognition Error:', event.error);\n\n        if (event.error === 'no-speech') {\n            alert('No speech detected. Please try again.');\n            setTimeout(() => {\n                startSpeechRecognition();\n            }, 1000); // Restart after 1 second\n        }\n\n        if (event.error === 'audio-capture') {\n            alert('Please check your microphone permissions.');\n        }\n    };\n}\n\n// Function to request microphone permission\nasync function requestMicPermission() {\n    try {\n        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n        console.log('Microphone permission granted');\n        stream.getTracks().forEach(track => track.stop());  // Stop the stream immediately\n        return true;\n    } catch (error) {\n        console.error('Microphone permission denied:', error);\n        alert('Microphone access is required for speech recognition.');\n        return false;\n    }\n}\n\n// Start speech recognition function\nexport async function startSpeechRecognition() {\n    const permissionGranted = await requestMicPermission();  // Ensure permission is granted\n    if (!permissionGranted) return;\n\n    if (isRecognitionRunning) {\n        console.error(\"Speech recognition is already running.\");\n        return;\n    }\n\n    finalTranscript = '';  // Clear transcript on new session\n    initializeRecognition();  // Initialize the recognition instance\n    try {\n        recognition.start();\n        isRecognitionRunning = true;\n        console.log('Speech recognition started.');\n    } catch (error) {\n        console.error('Error starting speech recognition:', error);\n    }\n}\n\n// Stop speech recognition function\nexport function stopSpeechRecognition() {\n    if (!isRecognitionRunning) {\n        console.error(\"Speech recognition is not running.\");\n        return;\n    }\n    console.log('Stopping speech recognition...');\n    recognition.stop();  // Stop recognition\n    isRecognitionRunning = false; // Mark recognition as stopped\n}\n\n// Process the final transcript and send to backend\nexport const processTranscript = async (transcript) => {\n    try {\n        // Send as JSON, because the backend likely expects a JSON payload\n        const response = await fetch('http://localhost:3001/generateNotes', {\n            method: 'POST',\n            headers: {\n                'Content-Type': 'application/json',\n            },\n            body: JSON.stringify({ transcript }),  // Send the transcript as JSON\n        });\n\n        if (!response.ok) {\n            throw new Error(`Server error: ${response.status}`);\n        }\n\n        const result = await response.json();\n        console.log('Generated notes:', result);\n    } catch (error) {\n        console.error('Error sending transcript to backend:', error);\n    }\n};\n"],"mappings":"AAAA,IAAIA,oBAAoB,GAAG,KAAK;AAChC,IAAIC,eAAe,GAAG,EAAE,CAAC,CAAE;;AAE3B;AACA,SAASC,6BAA6BA,CAAA,EAAG;EACrCC,MAAM,CAACC,iBAAiB,GAAGD,MAAM,CAACC,iBAAiB,IAAID,MAAM,CAACE,uBAAuB;EACrF,IAAI,CAACF,MAAM,CAACC,iBAAiB,EAAE;IAC3BE,OAAO,CAACC,KAAK,CAAC,sCAAsC,CAAC;IACrDC,KAAK,CAAC,4DAA4D,CAAC;IACnE,OAAO,KAAK;EAChB;EACA,OAAO,IAAI;AACf;;AAEA;AACA,IAAI,CAACN,6BAA6B,CAAC,CAAC,EAAE;EAClCM,KAAK,CAAC,0EAA0E,CAAC;AACrF;;AAEA;AACA,SAASC,qBAAqBA,CAAA,EAAG;EAC7BC,WAAW,GAAG,IAAIP,MAAM,CAACC,iBAAiB,CAAC,CAAC;EAC5CM,WAAW,CAACC,UAAU,GAAG,IAAI;EAC7BD,WAAW,CAACE,cAAc,GAAG,IAAI,CAAC,CAAC;EACnCF,WAAW,CAACG,IAAI,GAAG,OAAO;EAE1BH,WAAW,CAACI,QAAQ,GAAIC,KAAK,IAAK;IAC9B,IAAIC,iBAAiB,GAAG,EAAE;;IAE1B;IACA,KAAK,IAAIC,CAAC,GAAGF,KAAK,CAACG,WAAW,EAAED,CAAC,GAAGF,KAAK,CAACI,OAAO,CAACC,MAAM,EAAEH,CAAC,EAAE,EAAE;MAC3D,MAAMI,MAAM,GAAGN,KAAK,CAACI,OAAO,CAACF,CAAC,CAAC;;MAE/B;MACA,IAAII,MAAM,CAACC,OAAO,EAAE;QAChBrB,eAAe,IAAIoB,MAAM,CAAC,CAAC,CAAC,CAACE,UAAU,CAAC,CAAE;MAC9C,CAAC,MAAM;QACHP,iBAAiB,IAAIK,MAAM,CAAC,CAAC,CAAC,CAACE,UAAU,CAAC,CAAE;MAChD;IACJ;;IAEA;IACAjB,OAAO,CAACkB,GAAG,CAAC,qBAAqB,EAAER,iBAAiB,CAAC;;IAErD;IACAV,OAAO,CAACkB,GAAG,CAAC,0BAA0B,EAAEvB,eAAe,CAAC;EAC5D,CAAC;;EAED;EACAS,WAAW,CAACe,KAAK,GAAG,MAAM;IACtBnB,OAAO,CAACkB,GAAG,CAAC,6BAA6B,CAAC;;IAE1C;IACA,IAAIvB,eAAe,EAAE;MACjBK,OAAO,CAACkB,GAAG,CAAC,sCAAsC,CAAC;MACnDE,iBAAiB,CAACzB,eAAe,CAAC,CAAC,CAAE;MACrCA,eAAe,GAAG,EAAE,CAAC,CAAE;IAC3B;;IAEA;IACA,IAAID,oBAAoB,EAAE;MACtBM,OAAO,CAACkB,GAAG,CAAC,kCAAkC,CAAC;MAC/Cd,WAAW,CAACiB,KAAK,CAAC,CAAC,CAAC,CAAE;IAC1B;EACJ,CAAC;;EAED;EACAjB,WAAW,CAACkB,OAAO,GAAIb,KAAK,IAAK;IAC7BT,OAAO,CAACC,KAAK,CAAC,2BAA2B,EAAEQ,KAAK,CAACR,KAAK,CAAC;IAEvD,IAAIQ,KAAK,CAACR,KAAK,KAAK,WAAW,EAAE;MAC7BC,KAAK,CAAC,uCAAuC,CAAC;MAC9CqB,UAAU,CAAC,MAAM;QACbC,sBAAsB,CAAC,CAAC;MAC5B,CAAC,EAAE,IAAI,CAAC,CAAC,CAAC;IACd;IAEA,IAAIf,KAAK,CAACR,KAAK,KAAK,eAAe,EAAE;MACjCC,KAAK,CAAC,2CAA2C,CAAC;IACtD;EACJ,CAAC;AACL;;AAEA;AACA,eAAeuB,oBAAoBA,CAAA,EAAG;EAClC,IAAI;IACA,MAAMC,MAAM,GAAG,MAAMC,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;MAAEC,KAAK,EAAE;IAAK,CAAC,CAAC;IACzE9B,OAAO,CAACkB,GAAG,CAAC,+BAA+B,CAAC;IAC5CQ,MAAM,CAACK,SAAS,CAAC,CAAC,CAACC,OAAO,CAACC,KAAK,IAAIA,KAAK,CAACC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAE;IACpD,OAAO,IAAI;EACf,CAAC,CAAC,OAAOjC,KAAK,EAAE;IACZD,OAAO,CAACC,KAAK,CAAC,+BAA+B,EAAEA,KAAK,CAAC;IACrDC,KAAK,CAAC,uDAAuD,CAAC;IAC9D,OAAO,KAAK;EAChB;AACJ;;AAEA;AACA,OAAO,eAAesB,sBAAsBA,CAAA,EAAG;EAC3C,MAAMW,iBAAiB,GAAG,MAAMV,oBAAoB,CAAC,CAAC,CAAC,CAAE;EACzD,IAAI,CAACU,iBAAiB,EAAE;EAExB,IAAIzC,oBAAoB,EAAE;IACtBM,OAAO,CAACC,KAAK,CAAC,wCAAwC,CAAC;IACvD;EACJ;EAEAN,eAAe,GAAG,EAAE,CAAC,CAAE;EACvBQ,qBAAqB,CAAC,CAAC,CAAC,CAAE;EAC1B,IAAI;IACAC,WAAW,CAACiB,KAAK,CAAC,CAAC;IACnB3B,oBAAoB,GAAG,IAAI;IAC3BM,OAAO,CAACkB,GAAG,CAAC,6BAA6B,CAAC;EAC9C,CAAC,CAAC,OAAOjB,KAAK,EAAE;IACZD,OAAO,CAACC,KAAK,CAAC,oCAAoC,EAAEA,KAAK,CAAC;EAC9D;AACJ;;AAEA;AACA,OAAO,SAASmC,qBAAqBA,CAAA,EAAG;EACpC,IAAI,CAAC1C,oBAAoB,EAAE;IACvBM,OAAO,CAACC,KAAK,CAAC,oCAAoC,CAAC;IACnD;EACJ;EACAD,OAAO,CAACkB,GAAG,CAAC,gCAAgC,CAAC;EAC7Cd,WAAW,CAAC8B,IAAI,CAAC,CAAC,CAAC,CAAE;EACrBxC,oBAAoB,GAAG,KAAK,CAAC,CAAC;AAClC;;AAEA;AACA,OAAO,MAAM0B,iBAAiB,GAAG,MAAOH,UAAU,IAAK;EACnD,IAAI;IACA;IACA,MAAMoB,QAAQ,GAAG,MAAMC,KAAK,CAAC,qCAAqC,EAAE;MAChEC,MAAM,EAAE,MAAM;MACdC,OAAO,EAAE;QACL,cAAc,EAAE;MACpB,CAAC;MACDC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;QAAE1B;MAAW,CAAC,CAAC,CAAG;IAC3C,CAAC,CAAC;IAEF,IAAI,CAACoB,QAAQ,CAACO,EAAE,EAAE;MACd,MAAM,IAAIC,KAAK,CAAC,iBAAiBR,QAAQ,CAACS,MAAM,EAAE,CAAC;IACvD;IAEA,MAAM/B,MAAM,GAAG,MAAMsB,QAAQ,CAACU,IAAI,CAAC,CAAC;IACpC/C,OAAO,CAACkB,GAAG,CAAC,kBAAkB,EAAEH,MAAM,CAAC;EAC3C,CAAC,CAAC,OAAOd,KAAK,EAAE;IACZD,OAAO,CAACC,KAAK,CAAC,sCAAsC,EAAEA,KAAK,CAAC;EAChE;AACJ,CAAC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}